{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jak062/TrainVocModel/blob/main/RV%D0%A1_Politrees_27_05_24_%7C%7C_RU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "<center>\n",
        "\n",
        "</a>\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "</center>\n",
        "<small>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "<details>\n",
        "<summary><b>–ü–ª–∞–Ω—ã –Ω–∞ –±—É–¥—É—â–µ–µ</b></summary>\n",
        "\n",
        "* –î–µ—Ç–µ–∫—Ç–æ—Ä –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
        "* –ë–æ–ª—å—à–µ –ø—Ä–µ—Ç—Ä–µ–π–Ω–æ–≤\n",
        "* TTS\n",
        "* –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
        "* –û–±–ª–µ–≥—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\n",
        "* –ù–æ–≤—ã–µ Gr–∞di–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "<summary><b>–°–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π</b></summary>\n",
        "\n",
        "+ <u><b>27.05.24</b></u>\n",
        "  <details>\n",
        "  <summary><b>–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ –≤–∫–ª–∞–¥–∫–µ UVR</b></summary>\n",
        "\n",
        "  <small>\n",
        "\n",
        "  + –î–æ–±–∞–≤–ª–µ–Ω–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è - **Mel Band Roformer**.\n",
        "  + –ò–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π —Å—Ç–∞–ª–∏ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω—ã–º–∏.\n",
        "  \n",
        "  </small>\n",
        "  </details>\n",
        "\n",
        "+ <u><b>23.05.24</b></u>\n",
        "  <details>\n",
        "  <summary><b>–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ –≤–∫–ª–∞–¥–∫–µ –¢–†–ï–ù–ò–†–û–í–ö–ê</b></summary>\n",
        "\n",
        "  <small>\n",
        "\n",
        "  + –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–µ—Ç—Ä–µ–π–Ω `\"TITAN-Medium\"` - 48k.\n",
        "  + –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–µ—Ç—Ä–µ–π–Ω `\"SingerPretrain\"` - 32k.\n",
        "  + –ù–µ–±–æ–ª—å—à–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "  + –£–±—Ä–∞–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `is_half` –∏–∑ –∑–∞ –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏.\n",
        "  \n",
        "  </small>\n",
        "  </details>\n",
        "\n",
        "+ <u><b>16.05.24</b></u>\n",
        "  <details>\n",
        "  <summary><b>–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ –≤–∫–ª–∞–¥–∫–µ –¢–†–ï–ù–ò–†–û–í–ö–ê</b></summary>\n",
        "\n",
        "  <small>\n",
        "\n",
        "  + –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `sample_rate`.\n",
        "  + –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `is_half`.\n",
        "  + –£–ª—É—á—à–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏.\n",
        "  + –£–ª—É—á—à–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
        "  \n",
        "  </small>\n",
        "  </details>\n",
        "\n",
        "+ <u><b>29.04.24</b></u>\n",
        "  <details>\n",
        "  <summary><b>–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ –≤–∫–ª–∞–¥–∫–µ UVR</b></summary>\n",
        "\n",
        "  <small>\n",
        "\n",
        "  + –£–±—Ä–∞–Ω–∞ –≤–∫–ª–∞–¥–∫–∞ \"**UVR (2 –≤–∞—Ä–∏–∞–Ω—Ç)**\"\n",
        "  + –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å—Ç–∞–ª –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–º.\n",
        "\n",
        "  </small>\n",
        "  </details>\n",
        "\n",
        "+ <u><b>27.04.24</b></u>\n",
        "  <details>\n",
        "  <summary><b>–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ –≤–∫–ª–∞–¥–∫–µ –¢–†–ï–ù–ò–†–û–í–ö–ê</b></summary>\n",
        "\n",
        "  <small>\n",
        "\n",
        "  > **–ò–∑–º–µ–Ω–µ–Ω–∏—è:**\n",
        "  + –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å—Ç–∞–ª –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º.\n",
        "  + –£–ª—É—á—à–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU.\n",
        "  + –£–ª—É—á—à–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π.\n",
        "  + –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–ø—Ä—è—Ç–∞–Ω–∞ –∑–∞ –≤–∫–ª–∞–¥–∫–∞–º–∏.\n",
        "  + –£–±—Ä–∞–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `sample_rate` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - 40k).\n",
        "  + –£–±—Ä–∞–Ω—ã –ø—Ä–µ—Ç—Ä–µ–π–Ω—ã, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ `sample_rate = 40k`.\n",
        "  + –ü–∞—Ä–∞–º–µ—Ç—Ä—ã `epochs` –∏ `save_epoch` –∏–∑–º–µ–Ω–µ–Ω—ã —Å–æ —Å–ª–∞–π–¥–µ—Ä–æ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è.\n",
        "\n",
        "  > **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**\n",
        "  + –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º `sample_rate`.\n",
        "  + –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º –ø—Ä–µ—Ç—Ä–µ–π–Ω–æ–≤.\n",
        "  \n",
        "  </small>\n",
        "  </details>\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "r4ihJIzbgfK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FF8C00'> **<big> <<< –¢–†–ï–ù–ò–†–û–í–ö–ê**"
      ],
      "metadata": {
        "id": "XnIUS5P9VauG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< –¢–†–ï–ù–ò–†–û–í–ö–ê –ú–û–î–ï–õ–ò**"
      ],
      "metadata": {
        "id": "O_27mvQ9mZjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb5fzhzEXK8X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <big>‚¨áÔ∏è **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ RVC**\n",
        "\n",
        "print(\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU...\")\n",
        "\n",
        "import os, torch\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nGPU –¥–æ—Å—Ç—É–ø–µ–Ω!\\n\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"\\nGPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!\\n\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    raise Exception('–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ GPU –Ω–∞ –≤–∞—à–µ–º —Ç–µ–∫—É—â–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ GPU, –∏–ª–∏ –ø–æ–¥–æ–∂–¥–∏—Ç–µ 24 —á–∞—Å–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É.')\n",
        "\n",
        "\n",
        "if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    os.makedirs('/content/drive/MyDrive')\n",
        "if not os.path.exists('/content/dataset'):\n",
        "    os.makedirs('/content/dataset')\n",
        "\n",
        "if not os.path.isdir('/content/drive/MyDrive/TrainingModel'):\n",
        "    print(\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...\")\n",
        "    !git clone https://github.com/Bebra777228/TrainVocModel-EN /content/drive/MyDrive/TrainingModel &> /dev/null\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 5 –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
        "print('\\n–ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–π–º–µ—Ç –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ–Ω–∞ –∑–∞–≤–∏—Å–ª–∞ –∏ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å colab. \\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é \"–°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\" -> \"–û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —É–¥–∞–ª–∏—Ç—å –µ–µ\", –ª–∏–±–æ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç.')\n",
        "print(\"\\n–ü–æ –ª—é–±—ã–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º, –ø–∏—à–∏—Ç–µ –≤ tg: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n",
        "!python download_files.py &> /dev/null\n",
        "\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "installed = True\n",
        "Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big> ‚õèÔ∏è **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö**\n",
        "\n",
        "import os, re, faiss, traceback\n",
        "import numpy as np\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from multiprocessing import cpu_count\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **–î–∞–π—Ç–µ –∏–º—è —Å–≤–æ–µ–π –º–æ–¥–µ–ª–∏ `(–ù–∞–ø—Ä–∏–º–µ—Ä - Sanya)`:**\n",
        "model_name = 'Model_Name' #@param {type:\"string\"}\n",
        "if not re.match(r'^[\\w_]+$', model_name):\n",
        "    raise ValueError(\"–ò–º—è –º–æ–¥–µ–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã!\")\n",
        "#@markdown * **–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∞—É–¥–∏–æ `(–¥–∞—Ç–∞—Å–µ—Ç)`:**\n",
        "dataset_folder = '/content/dataset' #@param {type:\"string\"}\n",
        "if not os.listdir(dataset_folder):\n",
        "    raise FileNotFoundError(\"–ü–∞–ø–∫–∞ —Å –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞!\")\n",
        "#@markdown ---\n",
        "#@markdown * **–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö:**\n",
        "f0method = \"rmvpe_gpu\" #@param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
        "#@markdown * **–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏:**\n",
        "sample_rate = \"40k\"  # @param [\"32k\", \"40k\", \"48k\"]\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "is_half = True  # –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏\n",
        "\n",
        "\n",
        "##################################################\n",
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "##################################################\n",
        "\n",
        "!mkdir -p ./logs/{model_name}\n",
        "with open(f'./logs/{model_name}/preprocess.log','w') as f:\n",
        "    print(\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç...\")\n",
        "!python infer/modules/train/preprocess.py {dataset_folder} {sr} 2 ./logs/{model_name} False 5.0 > /dev/null 2>&1\n",
        "with open(f'./logs/{model_name}/preprocess.log','r') as f:\n",
        "    if 'end preprocess' in f.read():\n",
        "        clear_output()\n",
        "    else:\n",
        "        print(\"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö... –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ —Å –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –≤—ã–±—Ä–∞–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.\")\n",
        "\n",
        "##################################################\n",
        "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
        "##################################################\n",
        "\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
        "    print(\"–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏...\")\n",
        "if f0method != \"rmvpe_gpu\":\n",
        "    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n",
        "else:\n",
        "    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} {is_half}\n",
        "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 ./logs/{model_name} v2 {is_half}\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
        "    if 'all-feature-done' in f.read():\n",
        "        clear_output()\n",
        "    else:\n",
        "        print(\"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö... –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ —Å –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –≤—ã–±—Ä–∞–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.\")\n",
        "\n",
        "##################################################\n",
        "# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∏–Ω–¥–µ–∫—Å–∞\n",
        "##################################################\n",
        "\n",
        "def train_index(exp_dir1, version19):\n",
        "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if not os.path.exists(feature_dir):\n",
        "        return \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!\"\n",
        "    listdir_res = list(os.listdir(feature_dir))\n",
        "    if len(listdir_res) == 0:\n",
        "        return \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!\"\n",
        "    infos = []\n",
        "    npys = []\n",
        "    for name in sorted(listdir_res):\n",
        "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "        npys.append(phone)\n",
        "    big_npy = np.concatenate(npys, 0)\n",
        "    big_npy_idx = np.arange(big_npy.shape[0])\n",
        "    np.random.shuffle(big_npy_idx)\n",
        "    big_npy = big_npy[big_npy_idx]\n",
        "    if big_npy.shape[0] > 2e5:\n",
        "        infos.append(\"–ü–æ–ø—ã—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è kmeans %s —Ñ–æ—Ä–º—ã –¥–æ 100–∫ —Ü–µ–Ω—Ç—Ä–æ–≤.\" % big_npy.shape[0])\n",
        "        yield \"\\n\".join(infos)\n",
        "        try:\n",
        "            big_npy = (\n",
        "                MiniBatchKMeans(\n",
        "                    n_clusters=100000,\n",
        "                    verbose=True,\n",
        "                    batch_size=256 * cpu_count(),\n",
        "                    compute_labels=False,\n",
        "                    init=\"random\",\n",
        "                )\n",
        "                .fit(big_npy)\n",
        "                .cluster_centers_\n",
        "            )\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            logger.info(info)\n",
        "            infos.append(info)\n",
        "            yield \"\\n\".join(infos)\n",
        "\n",
        "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "    yield \"\\n\".join(infos)\n",
        "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "    infos.append(\"–æ–±—É—á–µ–Ω–∏–µ\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    index_ivf = faiss.extract_index_ivf(index)  #\n",
        "    index_ivf.nprobe = 1\n",
        "    index.train(big_npy)\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "\n",
        "    infos.append(\"–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    batch_size_add = 8192\n",
        "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "        index.add(big_npy[i : i + batch_size_add])\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "    infos.append(\n",
        "        \"—É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω –∏–Ω–¥–µ–∫—Å, added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
        "    )\n",
        "\n",
        "training_log = train_index(model_name, 'v2')\n",
        "\n",
        "for line in training_log:\n",
        "    print(line)\n",
        "    if '–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ' in line:\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\"))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c9a4PKyP1yQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>ü§ñ **–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏**\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "from random import shuffle\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from IPython.display import clear_output\n",
        "\n",
        "now_dir=os.getcwd()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:** `(–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 200-800)`\n",
        "epochs = \"500\" # @param {type:\"string\"}\n",
        "#@markdown * **–ß–∞—Å—Ç–æ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ –¥–∏—Å–∫:** `(–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 5-25)`\n",
        "save_epoch = \"20\" # @param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown * **–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:**\n",
        "pretrain = \"¬ª Default - 32k/40k/48k\" # @param [\"¬ª Default - 32k/40k/48k\", \"\", \"–†–£–°–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª Snowie v2 - 40k/48k\", \"¬ª Snowie v3 - 32k/40k/48k\", \"\", \"–ê–ù–ì–õ–ò–ô–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª Ov2Super - 40k\", \"¬ª RIN_E3 - 40k\", \"¬ª TITAN-Medium - 32k/40k/48k\", \"¬ª DMR (ASMR) - 32k\", \"¬ª SingerPretrain - 32k\", \"\", \"–ë–†–ò–¢–ê–ù–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª UKR - 32k\", \"¬ª UKA - 32k\", \"\", \"–ò–¢–ê–õ–¨–Ø–ù–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª ItaIla - 32k\", \"\", \"–ö–û–†–ï–ô–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª KLMv7s - 32k\", \"¬ª KLMv7s v2 - 32k/40k/48k\", \"¬ª KLMv7s v3 - 32k/40k/48k\", \"\", \"–ì–ò–ë–†–ò–î–´:\", \"¬ª Snowie v3 x RIN_E3 - 40k\"]\n",
        "batch_size = 8  # @param {type:\"slider\", min:4, max:16, step:4}\n",
        "#@markdown ---\n",
        "\n",
        "print(\"–ó–∞–ø—É—Å–∫...\")\n",
        "\n",
        "param_aria = \"--con\" + \"sole-l\" + \"og-le\" + \"vel=er\" + \"ror -c -x 1\" + \"6 -s 1\" + \"6 -k 1\" + \"M\"\n",
        "hugg_pret = \"ht\" + \"tps:/\" + \"/hug\" + \"gingf\" + \"ace.co\" + \"/Poli\" + \"tree\" + \"s/all\" + \"_RV\" + \"C-pre\" + \"tra\" + \"ined_an\" + \"d_oth\" + \"er/re\" + \"solv\" + \"e/mai\" + \"n/pre\" + \"tra\" + \"ine\" + \"d/v2\"\n",
        "pretrain_outpath = \"/content/pretrained_models\"\n",
        "\n",
        "!apt -y install -qq aria2 &> /dev/null\n",
        "!rm -r /content/pretrained_models  &> /dev/null\n",
        "clear_output()\n",
        "\n",
        "models = {\n",
        "    \"¬ª Default - 32k/40k/48k\": [(f\"{sample_rate}/Default/f0D{sample_rate}.pth\", f\"default_D{sample_rate}.pth\"), (f\"{sample_rate}/Default/f0G{sample_rate}.pth\", f\"default_G{sample_rate}.pth\")],\n",
        "    \"¬ª Snowie v2 - 40k/48k\": [(f\"{sample_rate}/Snowie/D_Snowie_RuPretrain_{sample_rate}.pth\", f\"SnowieV2_D{sample_rate}.pth\"), (f\"{sample_rate}/Snowie/G_Snowie_RuPretrain_{sample_rate}.pth\", f\"SnowieV2_G{sample_rate}.pth\")],\n",
        "    \"¬ª Snowie v3 - 32k/40k/48k\": [(f\"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_D{sample_rate}.pth\"), (f\"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_G{sample_rate}.pth\")],\n",
        "    \"¬ª Ov2Super - 40k\": [(f\"{sample_rate}/Ov2/f0Ov2Super{sample_rate}D.pth\", f\"Ov2Super_D{sample_rate}.pth\"), (f\"{sample_rate}/Ov2/f0Ov2Super{sample_rate}G.pth\", f\"Ov2Super_G{sample_rate}.pth\")],\n",
        "    \"¬ª RIN_E3 - 40k\": [(f\"{sample_rate}/RIN_E/D_RIN_E3.pth\", f\"Rin_E3_D{sample_rate}.pth\"), (f\"{sample_rate}/RIN_E/G_RIN_E3.pth\", f\"Rin_E3_G{sample_rate}.pth\")],\n",
        "    \"¬ª TITAN-Medium - 32k/40k/48k\": [(f\"{sample_rate}/TITAN/D-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_D{sample_rate}.pth\"), (f\"{sample_rate}/TITAN/G-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_G{sample_rate}.pth\")],\n",
        "    \"¬ª UKR - 32k\": [(f\"{sample_rate}/UK/UKR-Pretrain-D.pth\", f\"UKR_D{sample_rate}.pth\"), (f\"{sample_rate}/UK/UKR-Pretrain-G.pth\", f\"UKR_G{sample_rate}.pth\")],\n",
        "    \"¬ª UKA - 32k\": [(f\"{sample_rate}/UK/UKA-Pretrain-D.pth\", f\"UKA_D{sample_rate}.pth\"), (f\"{sample_rate}/UK/UKA-Pretrain-G.pth\", f\"UKA_G{sample_rate}.pth\")],\n",
        "    \"¬ª DMR (ASMR) - 32k\": [(f\"{sample_rate}/DMR/D_dmrV0-5.pth\", f\"DMR_D{sample_rate}.pth\"), (f\"{sample_rate}/DMR/G_dmrV0-5.pth\", f\"DMR_G{sample_rate}.pth\")],\n",
        "    \"¬ª ItaIla - 32k\": [(f\"{sample_rate}/Italla/ItaIla_{sample_rate}_D.pth\", f\"ItaIla_D{sample_rate}.pth\"), (f\"{sample_rate}/Italla/ItaIla_{sample_rate}_G.pth\", f\"ItaIla_G{sample_rate}.pth\")],\n",
        "    \"¬ª KLMv7s - 32k\": [(f\"{sample_rate}/KLMv7s/D_KLM_V7s_{sample_rate}.pth\", f\"KLMv7_D{sample_rate}.pth\"), (f\"{sample_rate}/KLMv7s/G_KLM_V7s_{sample_rate}.pth\", f\"KLMv7_G{sample_rate}.pth\")],\n",
        "    \"¬ª KLMv7s v2 - 32k/40k/48k\": [(f\"{sample_rate}/KLMv7s/D_KLMv7s_Batch2_{sample_rate}.pth\", f\"KLMv7_v2_D{sample_rate}.pth\"), (f\"{sample_rate}/KLMv7s/G_KLMv7s_Batch2_{sample_rate}.pth\", f\"KLMv7_v2_G{sample_rate}.pth\")],\n",
        "    \"¬ª KLMv7s v3 - 32k/40k/48k\": [(f\"{sample_rate}/KLMv7s/D_KLMv7s_Batch3C_{sample_rate}.pth\", f\"KLMv7_v3_D{sample_rate}.pth\"), (f\"{sample_rate}/KLMv7s/G_KLMv7s_Batch3C_{sample_rate}.pth\", f\"KLMv7_v3_G{sample_rate}.pth\")],\n",
        "    \"¬ª Snowie v3 x RIN_E3 - 40k\": [(f\"{sample_rate}/Snowie/D_Snowie-X-Rin_{sample_rate}.pth\", f\"Snowiev3_x_RINe3_D{sample_rate}.pth\"), (f\"{sample_rate}/Snowie/G_Snowie-X-Rin_{sample_rate}.pth\", f\"Snowiev3_x_RINe3_G{sample_rate}.pth\")],\n",
        "    \"¬ª SingerPretrain - 32k\": [(f\"{sample_rate}/SingerPretrain/f0D_SingerPreTrain.pth\", f\"Singer_D{sample_rate}.pth\"), (f\"{sample_rate}/SingerPretrain/f0G_SingerPreTrain.pth\", f\"Singer_G{sample_rate}.pth\")]\n",
        "}\n",
        "\n",
        "print(f\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ—Ç—Ä–µ–π–Ω–∞ {pretrain}...\")\n",
        "for f in models[pretrain]:\n",
        "    !aria2c {param_aria} {hugg_pret}/{f[0]} -d {pretrain_outpath} -o {f[1]} &> /dev/null\n",
        "\n",
        "G_file = f'{pretrain_outpath}/{models[pretrain][1][1]}'\n",
        "D_file = f'{pretrain_outpath}/{models[pretrain][0][1]}'\n",
        "\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    print(\"–ó–∞–ø–∏—Å—å —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n",
        "    print(\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"–ù–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"–ë–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = f\"configs/v1/{sr2}.json\"\n",
        "    else:\n",
        "        config_path = f\"configs/v2/{sr2}.json\"\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                config_data[\"train\"][\"log_interval\"] = 200\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"\\n–ó–∞–ø–∏—Å—å —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\\n\")\n",
        "    print(\"–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã...\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
        "        % (\n",
        "            exp_dir1,\n",
        "            sr2,\n",
        "            1 if if_f0_3 else 0,\n",
        "            batch_size12,\n",
        "            gpus16,\n",
        "            total_epoch11,\n",
        "            save_epoch10,\n",
        "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
        "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
        "            1 if if_save_latest13 == True else 0,\n",
        "            1 if if_cache_gpu17 == True else 0,\n",
        "            1 if if_save_every_weights18 == True else 0,\n",
        "            version19,\n",
        "        )\n",
        "    )\n",
        "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    for line in p.stdout:\n",
        "        print(line.strip())\n",
        "\n",
        "    p.wait()\n",
        "    return \"–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–∫—Ä—ã—Ç–∞.\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs --port=8888\n",
        "if \"cache\" not in locals():\n",
        "    cache = False\n",
        "training_log = click_train(\n",
        "    model_name,\n",
        "    sample_rate,\n",
        "    True,\n",
        "    0,\n",
        "    save_epoch,\n",
        "    epochs,\n",
        "    batch_size,\n",
        "    True,\n",
        "    G_file,\n",
        "    D_file,\n",
        "    0,\n",
        "    cache,\n",
        "    True,\n",
        "    'v2',\n",
        ")\n",
        "print(training_log)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WSWzfETu12lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< –ü–†–û–î–û–õ–ñ–ò–¢–¨ –¢–†–ï–ù–ò–†–û–í–ö–£ –ú–û–î–ï–õ–ò**"
      ],
      "metadata": {
        "id": "8q3V33sNvi6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>‚¨áÔ∏è **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ RVC**\n",
        "\n",
        "print(\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU...\")\n",
        "\n",
        "import os, torch\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nGPU –¥–æ—Å—Ç—É–ø–µ–Ω!\\n\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"\\nGPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!\\n\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    raise Exception('–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ GPU –Ω–∞ –≤–∞—à–µ–º —Ç–µ–∫—É—â–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ GPU, –∏–ª–∏ –ø–æ–¥–æ–∂–¥–∏—Ç–µ 24 —á–∞—Å–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É.')\n",
        "\n",
        "\n",
        "if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    os.makedirs('/content/drive/MyDrive')\n",
        "if not os.path.exists('/content/dataset'):\n",
        "    os.makedirs('/content/dataset')\n",
        "\n",
        "if not os.path.isdir('/content/drive/MyDrive/TrainingModel'):\n",
        "    raise Exception(\"–ü–∞–ø–∫–∞ TrainingModel –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –±–µ–∑ —Å–∞–º–æ–π –º–æ–¥–µ–ª–∏.\")\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 5 –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
        "print('\\n–ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–π–º–µ—Ç –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ–Ω–∞ –∑–∞–≤–∏—Å–ª–∞ –∏ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å colab. \\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é \"–°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\" -> \"–û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —É–¥–∞–ª–∏—Ç—å –µ–µ\", –ª–∏–±–æ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç.')\n",
        "print(\"\\n–ü–æ –ª—é–±—ã–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º, –ø–∏—à–∏—Ç–µ –≤ tg: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n",
        "\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "installed = True\n",
        "Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\")"
      ],
      "metadata": {
        "id": "ZqVvS-d-btU5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>ü§ñ **–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏**\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "from random import shuffle\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from IPython.display import clear_output\n",
        "\n",
        "now_dir=os.getcwd()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **–í–ø–∏—à–∏—Ç–µ –∏–º—è —Å–≤–æ–µ–π –º–æ–¥–µ–ª–∏:**\n",
        "model_name = 'Model_Name' #@param {type:\"string\"}\n",
        "#@markdown * **–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏:**\n",
        "sample_rate = \"40k\"  # @param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown ---\n",
        "#@markdown * **–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:** `(–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 200-800)`\n",
        "epochs = \"800\" # @param {type:\"string\"}\n",
        "#@markdown * **–ß–∞—Å—Ç–æ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ –¥–∏—Å–∫:** `(–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 5-25)`\n",
        "save_epoch = \"20\" # @param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown * **–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:**\n",
        "pretrain = \"¬ª Default - 32k/40k/48k\" # @param [\"¬ª Default - 32k/40k/48k\", \"\", \"–†–£–°–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª Snowie v2 - 40k/48k\", \"¬ª Snowie v3 - 32k/40k/48k\", \"\", \"–ê–ù–ì–õ–ò–ô–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª Ov2Super - 40k\", \"¬ª RIN_E3 - 40k\", \"¬ª TITAN-Medium - 32k/40k/48k\", \"¬ª DMR (ASMR) - 32k\", \"¬ª SingerPretrain - 32k\", \"\", \"–ë–†–ò–¢–ê–ù–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª UKR - 32k\", \"¬ª UKA - 32k\", \"\", \"–ò–¢–ê–õ–¨–Ø–ù–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª ItaIla - 32k\", \"\", \"–ö–û–†–ï–ô–°–ö–ò–ï –ü–†–ï–¢–†–ï–ô–ù–´:\", \"¬ª KLMv7s - 32k\", \"¬ª KLMv7s v2 - 32k/40k/48k\", \"¬ª KLMv7s v3 - 32k/40k/48k\", \"\", \"–ì–ò–ë–†–ò–î–´:\", \"¬ª Snowie v3 x RIN_E3 - 40k\"]\n",
        "batch_size = 8  # @param {type:\"slider\", min:4, max:16, step:4}\n",
        "#@markdown ---\n",
        "\n",
        "print(\"–ó–∞–ø—É—Å–∫...\")\n",
        "\n",
        "param_aria = \"--con\" + \"sole-l\" + \"og-le\" + \"vel=er\" + \"ror -c -x 1\" + \"6 -s 1\" + \"6 -k 1\" + \"M\"\n",
        "hugg_pret = \"ht\" + \"tps:/\" + \"/hug\" + \"gingf\" + \"ace.co\" + \"/Poli\" + \"tree\" + \"s/all\" + \"_RV\" + \"C-pre\" + \"tra\" + \"ined_an\" + \"d_oth\" + \"er/re\" + \"solv\" + \"e/mai\" + \"n/pre\" + \"tra\" + \"ine\" + \"d/v2\"\n",
        "pretrain_outpath = \"/content/pretrained_models\"\n",
        "\n",
        "!apt -y install -qq aria2 &> /dev/null\n",
        "!rm -r /content/pretrained_models  &> /dev/null\n",
        "clear_output()\n",
        "\n",
        "models = {\n",
        "    \"¬ª Default - 32k/40k/48k\": [(f\"{sample_rate}/Default/f0D{sample_rate}.pth\", f\"default_D{sample_rate}.pth\"), (f\"{sample_rate}/Default/f0G{sample_rate}.pth\", f\"default_G{sample_rate}.pth\")],\n",
        "    \"¬ª Snowie v2 - 40k/48k\": [(f\"{sample_rate}/Snowie/D_Snowie_RuPretrain_{sample_rate}.pth\", f\"SnowieV2_D{sample_rate}.pth\"), (f\"{sample_rate}/Snowie/G_Snowie_RuPretrain_{sample_rate}.pth\", f\"SnowieV2_G{sample_rate}.pth\")],\n",
        "    \"¬ª Snowie v3 - 32k/40k/48k\": [(f\"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_D{sample_rate}.pth\"), (f\"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_G{sample_rate}.pth\")],\n",
        "    \"¬ª Ov2Super - 40k\": [(f\"{sample_rate}/Ov2/f0Ov2Super{sample_rate}D.pth\", f\"Ov2Super_D{sample_rate}.pth\"), (f\"{sample_rate}/Ov2/f0Ov2Super{sample_rate}G.pth\", f\"Ov2Super_G{sample_rate}.pth\")],\n",
        "    \"¬ª RIN_E3 - 40k\": [(f\"{sample_rate}/RIN_E/D_RIN_E3.pth\", f\"Rin_E3_D{sample_rate}.pth\"), (f\"{sample_rate}/RIN_E/G_RIN_E3.pth\", f\"Rin_E3_G{sample_rate}.pth\")],\n",
        "    \"¬ª TITAN-Medium - 32k/40k/48k\": [(f\"{sample_rate}/TITAN/D-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_D{sample_rate}.pth\"), (f\"{sample_rate}/TITAN/G-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_G{sample_rate}.pth\")],\n",
        "    \"¬ª UKR - 32k\": [(f\"{sample_rate}/UK/UKR-Pretrain-D.pth\", f\"UKR_D{sample_rate}.pth\"), (f\"{sample_rate}/UK/UKR-Pretrain-G.pth\", f\"UKR_G{sample_rate}.pth\")],\n",
        "    \"¬ª UKA - 32k\": [(f\"{sample_rate}/UK/UKA-Pretrain-D.pth\", f\"UKA_D{sample_rate}.pth\"), (f\"{sample_rate}/UK/UKA-Pretrain-G.pth\", f\"UKA_G{sample_rate}.pth\")],\n",
        "    \"¬ª DMR (ASMR) - 32k\": [(f\"{sample_rate}/DMR/D_dmrV0-5.pth\", f\"DMR_D{sample_rate}.pth\"), (f\"{sample_rate}/DMR/G_dmrV0-5.pth\", f\"DMR_G{sample_rate}.pth\")],\n",
        "    \"¬ª ItaIla - 32k\": [(f\"{sample_rate}/Italla/ItaIla_{sample_rate}_D.pth\", f\"ItaIla_D{sample_rate}.pth\"), (f\"{sample_rate}/Italla/ItaIla_{sample_rate}_G.pth\", f\"ItaIla_G{sample_rate}.pth\")],\n",
        "    \"¬ª KLMv7s - 32k\": [(f\"{sample_rate}/KLMv7s/D_KLM_V7s_{sample_rate}.pth\", f\"KLMv7_D{sample_rate}.pth\"), (f\"{sample_rate}/KLMv7s/G_KLM_V7s_{sample_rate}.pth\", f\"KLMv7_G{sample_rate}.pth\")],\n",
        "    \"¬ª KLMv7s v2 - 32k/40k/48k\": [(f\"{sample_rate}/KLMv7s/D_KLMv7s_Batch2_{sample_rate}.pth\", f\"KLMv7_v2_D{sample_rate}.pth\"), (f\"{sample_rate}/KLMv7s/G_KLMv7s_Batch2_{sample_rate}.pth\", f\"KLMv7_v2_G{sample_rate}.pth\")],\n",
        "    \"¬ª KLMv7s v3 - 32k/40k/48k\": [(f\"{sample_rate}/KLMv7s/D_KLMv7s_Batch3C_{sample_rate}.pth\", f\"KLMv7_v3_D{sample_rate}.pth\"), (f\"{sample_rate}/KLMv7s/G_KLMv7s_Batch3C_{sample_rate}.pth\", f\"KLMv7_v3_G{sample_rate}.pth\")],\n",
        "    \"¬ª Snowie v3 x RIN_E3 - 40k\": [(f\"{sample_rate}/Snowie/D_Snowie-X-Rin_{sample_rate}.pth\", f\"Snowiev3_x_RINe3_D{sample_rate}.pth\"), (f\"{sample_rate}/Snowie/G_Snowie-X-Rin_{sample_rate}.pth\", f\"Snowiev3_x_RINe3_G{sample_rate}.pth\")],\n",
        "    \"¬ª SingerPretrain - 32k\": [(f\"{sample_rate}/SingerPretrain/f0D_SingerPreTrain.pth\", f\"Singer_D{sample_rate}.pth\"), (f\"{sample_rate}/SingerPretrain/f0G_SingerPreTrain.pth\", f\"Singer_G{sample_rate}.pth\")]\n",
        "}\n",
        "\n",
        "print(f\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ—Ç—Ä–µ–π–Ω–∞ {pretrain}...\")\n",
        "for f in models[pretrain]:\n",
        "    !aria2c {param_aria} {hugg_pret}/{f[0]} -d {pretrain_outpath} -o {f[1]} &> /dev/null\n",
        "\n",
        "G_file = f'{pretrain_outpath}/{models[pretrain][1][1]}'\n",
        "D_file = f'{pretrain_outpath}/{models[pretrain][0][1]}'\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    print(\"–ó–∞–ø–∏—Å—å —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n",
        "    print(\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"–ù–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"–ë–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = f\"configs/v1/{sr2}.json\"\n",
        "    else:\n",
        "        config_path = f\"configs/v2/{sr2}.json\"\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                config_data[\"train\"][\"log_interval\"] = 200\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"\\n–ó–∞–ø–∏—Å—å —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\\n\")\n",
        "    print(\"–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã...\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
        "        % (\n",
        "            exp_dir1,\n",
        "            sr2,\n",
        "            1 if if_f0_3 else 0,\n",
        "            batch_size12,\n",
        "            gpus16,\n",
        "            total_epoch11,\n",
        "            save_epoch10,\n",
        "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
        "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
        "            1 if if_save_latest13 == True else 0,\n",
        "            1 if if_cache_gpu17 == True else 0,\n",
        "            1 if if_save_every_weights18 == True else 0,\n",
        "            version19,\n",
        "        )\n",
        "    )\n",
        "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    for line in p.stdout:\n",
        "        print(line.strip())\n",
        "\n",
        "    p.wait()\n",
        "    return \"–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–∫—Ä—ã—Ç–∞.\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs --port=8888\n",
        "if \"cache\" not in locals():\n",
        "    cache = False\n",
        "training_log = click_train(\n",
        "    model_name,\n",
        "    sample_rate,\n",
        "    True,\n",
        "    0,\n",
        "    save_epoch,\n",
        "    epochs,\n",
        "    batch_size,\n",
        "    True,\n",
        "    G_file,\n",
        "    D_file,\n",
        "    0,\n",
        "    cache,\n",
        "    True,\n",
        "    'v2',\n",
        ")\n",
        "print(training_log)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NkqXOy7G2Pbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small>.</small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small>\n",
        "\n",
        "\n",
        "**<center><big><big><big><big>–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ –¥–∏—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏</center>**\n",
        "\n",
        "<center> –ü—É—Ç—å –∫ .pth —Ñ–∞–π–ª—É: </center>\n",
        "\n",
        "**<big><center><small> `TrainingModel/assets/weights/[–∏–º—è –º–æ–¥–µ–ª–∏].pth` </small></center></big>**\n",
        "\n",
        "<center> –ü—É—Ç—å –∫ .index —Ñ–∞–π–ª—É: </center>\n",
        "\n",
        "**<big><center><small> `TrainingModel/logs/[–∏–º—è –º–æ–¥–µ–ª–∏]/added_IVF[id]_Flat_nprobe_1_[–∏–º—è –º–æ–¥–µ–ª–∏]_v2.index` </small></center></big>**\n",
        "\n",
        "## <small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small>.</small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small>"
      ],
      "metadata": {
        "id": "QW3zegy0fj1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FF8C00'> **<big> <<< –ì–ï–ù–ï–†–ê–¢–û–†–´ –ö–ê–í–ï–†–û–í**"
      ],
      "metadata": {
        "id": "h76D42owRGmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–í–ï–†–û–í** <small>_(–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏)_"
      ],
      "metadata": {
        "id": "fZ3Kl6DJmtSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>‚¨áÔ∏è **–£–°–¢–ê–ù–û–í–ö–ê**\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import os, torch\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!\")\n",
        "    raise Exception('–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ GPU –Ω–∞ –≤–∞—à–µ–º —Ç–µ–∫—É—â–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ GPU, –∏–ª–∏ –ø–æ–¥–æ–∂–¥–∏—Ç–µ 24 —á–∞—Å–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É.')\n",
        "\n",
        "# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –¥–∏—Å–∫—É\n",
        "if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    os.makedirs('/content/drive/MyDrive')\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 5 –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
        "print('\\n–ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–π–º–µ—Ç –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ–Ω–∞ –∑–∞–≤–∏—Å–ª–∞ –∏ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å colab. \\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é \"–°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\" -> \"–û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —É–¥–∞–ª–∏—Ç—å –µ–µ\", –ª–∏–±–æ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç.')\n",
        "print(\"\\n–ü–æ –ª—é–±—ã–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º, –ø–∏—à–∏—Ç–µ –≤ tg: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!pip install --no-cache-dir -qq python-dotenv torchcrepe fairseq pyworld praat-parselmouth ffmpeg-python faiss-cpu av &> /dev/null\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø–∞–ø–æ–∫\n",
        "!mkdir -p /content/input\n",
        "!mkdir -p /content/output\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "28_80Dwvb7ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üîä **–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –≤–æ–∫–∞–ª–æ–º**\n",
        "\n",
        "#@markdown –ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π —Ñ–∞–π–ª –≤—Ä—É—á–Ω—É—é –≤ –ø–∞–ø–∫—É <big> **`input`**\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "\n",
        "# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã\n",
        "INPUT_DIR = \"/content/input\"\n",
        "VOCAL_FILE_NAME = \"vocal\"\n",
        "ALLOWED_EXTENSIONS = {'.mp3', '.wav'}\n",
        "\n",
        "os.chdir(INPUT_DIR)\n",
        "!rm -r /content/input/*\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –≤–æ–∫–∞–ª–æ–º\n",
        "audio = files.upload()\n",
        "clear_output()\n",
        "\n",
        "if not audio:\n",
        "    print(\"–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª.\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
        "ext = os.path.splitext(list(audio.keys())[-1])[-1].lower()\n",
        "if ext not in ALLOWED_EXTENSIONS:\n",
        "    !rm -r /content/input/*\n",
        "    print(f\"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ '{ext}'. –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —Å —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ {', '.join(ALLOWED_EXTENSIONS)}.\")\n",
        "    print(\"–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –¥—Ä—É–≥–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º, —Ç–æ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –µ–≥–æ –≤—Ä—É—á–Ω—É—é –≤ –ø–∞–ø–∫—É input.\")\n",
        "\n",
        "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "input_audio = VOCAL_FILE_NAME + ext\n",
        "os.rename(list(audio.keys())[-1], input_audio)\n",
        "\n",
        "clear_output()\n",
        "print(f\"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ejdaR2mX1CLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üó£Ô∏è **–ó–∞–º–µ–Ω–∞ –≥–æ–ª–æ—Å–∞**\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output, display, Audio\n",
        "from google.colab import files\n",
        "from ipywidgets import Button\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–í–≤–µ–¥–∏—Ç–µ –∏–º—è –º–æ–¥–µ–ª–∏ –∏ –∏–º—è <big>`.pth`</big> —Ñ–∞–π–ª–∞ *(–º–æ–∂–Ω–æ –≤–ø–∏—Å–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)*:**\n",
        "model_name = \"Model_Name\" #@param {type:\"string\"}\n",
        "pth_name = \"Model_Name_e120_s5280\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <big>**`_e120_s5280`**</big> - —ç—Ç–æ —Ç–æ—á–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. **–ï—Å–ª–∏ –≤—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ —Ç–æ—á–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —Ç–æ –≤–≤–µ–¥–∏—Ç–µ –≤ –ø–æ–ª–µ <big>`pth_name`</big> —Ç–æ –∂–µ —Å–∞–º–æ–µ, —á—Ç–æ –∏ –≤ –ø–æ–ª–µ <big>`model_name`</big>.**</big>\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–∞:**\n",
        "method = \"rmvpe\" #@param [\"rmvpe\", \"pm\", \"harvest\"] {allow-input: false}\n",
        "#@markdown **–í—ã—Å–æ—Ç–∞ —Ç–æ–Ω–∞ –≥–æ–ª–æ—Å–∞ ( -12 - –Ω–∞ –æ–∫—Ç–∞–≤—É –Ω–∏–∂–µ, 0 - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—É—é –≤—ã—Å–æ—Ç—É, 12 - –Ω–∞ –æ–∫—Ç–∞–≤—É –≤—ã—à–µ ):**\n",
        "pitch = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**\n",
        "\n",
        "#@markdown <small> –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∞–∫—Ü–µ–Ω—Ç –≥–æ–ª–æ—Å–∞ –ò–ò –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –≤–æ–∫–∞–ª–µ:\n",
        "index_rate = 0.66 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "volume_normalization = 1\n",
        "#@markdown <small> –ó–∞—â–∏—Ç–∞ –±–µ–∑–≥–æ–ª–æ—Å—ã—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö –∏ –∑–≤—É–∫–æ–≤ –¥—ã—Ö–∞–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. –£–º–µ–Ω—å—à–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É—Å–∏–ª–∏—Ç—å –∑–∞—â–∏—Ç—É, –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
        "consonant_protection = 0 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "#@markdown <small> –ï—Å–ª–∏ >=3: –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –º–µ–¥–∏–∞–Ω–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∫ —Å–æ–±—Ä–∞–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–∏—Ç—á–∞. –ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Ä–∞–¥–∏—É—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ –º–æ–∂–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å –¥—ã—Ö–∞–Ω–∏–µ:\n",
        "filter_radius = 3 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "is_half = False\n",
        "#@markdown **–§–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:**\n",
        "format = \"mp3\" #@param [\"mp3\", \"wav\", \"flac\"] {allow-input: false}\n",
        "\n",
        "input_path = '/content/input/*.*'\n",
        "model_path = f'{pth_name}.pth'\n",
        "index_path = f'logs/{model_name}/added_*_v2.index'\n",
        "opt_path = f'/content/output/output.{format}'\n",
        "\n",
        "# –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –Ω–æ–≤–æ–≥–æ\n",
        "!rm -r /content/output/*\n",
        "\n",
        "# –°–∫—Ä–∏–ø—Ç –∑–∞–º–µ–Ω—è—é—â–∏–π –≥–æ–ª–æ—Å\n",
        "!python tools/infer_cli.py --f0up_key $pitch --input_path $input_path --index_path $index_path --f0method $method --opt_path $opt_path --model_name $model_path --index_rate $index_rate --device cuda --is_half $is_half --filter_radius $filter_radius --resample_sr 0 --rms_mix_rate $volume_normalization --protect $consonant_protection\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <big><big> **–ü–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É –µ—Å–ª–∏ –≤—ã–ª–µ–∑–ª–∞ –æ—à–∏–±–∫–∞ –∏–ª–∏ –Ω–µ –ø–æ—è–≤–∏–ª—Å—è —Ñ–∞–π–ª, –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Å–∫–∏–Ω—å—Ç–µ —Å–∫—Ä–∏–Ω –æ—à–∏–±–∫–∏ –≤ —Ç–≥ https://t.me/+GMTP7hZqY0E4OGRi**\n",
        "check_error = False #@param {type:\"boolean\"}\n",
        "if not check_error:\n",
        "    ipd.clear_output()\n",
        "\n",
        "# –í—ã–≤–æ–¥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ \"–°–∫–∞—á–∞—Ç—å\"\n",
        "def download_file(file_path):\n",
        "    files.download(file_path)\n",
        "\n",
        "print(\"\\nGoogle Colab –∏–Ω–æ–≥–¥–∞ –Ω–µ –º–æ–∂–µ—Ç –≤—ã–≤–µ—Å—Ç–∏ –æ–∫–Ω–æ —Å –∞—É–¥–∏–æ, –ø–æ—ç—Ç–æ–º—É:\\n\")\n",
        "print(\"\\n1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–≤–æ–¥–∏–º –∫–Ω–æ–ø–∫—É '–°–∫–∞—á–∞—Ç—å', –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –≤—ã –º–æ–∂–µ—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –Ω–∞ –≤–∞—à–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.\\n\")\n",
        "\n",
        "download_button = Button(description=\"–°–∫–∞—á–∞—Ç—å\")\n",
        "display(download_button)\n",
        "download_button.on_click(lambda _: download_file(opt_path))\n",
        "\n",
        "print(\"\\n2. –ó–∞—Ç–µ–º, –í—ã–≤–æ–¥–∏–º —Å–∞–º—É –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –ø—Ä—è–º–æ –≤ Google Colab.\\n\")\n",
        "\n",
        "display(Audio(f\"{opt_path}\", rate=44100))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O9kgzXqI-sgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–í–ï–†–û–í**"
      ],
      "metadata": {
        "id": "Gp-DFix6G3Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üöÄ **–£–°–¢–ê–ù–û–í–ö–ê**\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import torch\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!\")\n",
        "    raise Exception('–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ GPU –Ω–∞ –≤–∞—à–µ–º —Ç–µ–∫—É—â–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ GPU, –∏–ª–∏ –ø–æ–¥–æ–∂–¥–∏—Ç–µ 24 —á–∞—Å–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É.')\n",
        "\n",
        "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n",
        "!git clone https://github.com/Bebra777228/TrainVocModel-EN /content/CoverGen &> /dev/null\n",
        "%cd /content/CoverGen\n",
        "clear_output()\n",
        "\n",
        "print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 5 –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
        "print('\\n–ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–π–º–µ—Ç –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ–Ω–∞ –∑–∞–≤–∏—Å–ª–∞ –∏ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å colab. \\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é \"–°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\" -> \"–û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —É–¥–∞–ª–∏—Ç—å –µ–µ\", –ª–∏–±–æ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç.')\n",
        "print(\"\\n–ü–æ –ª—é–±—ã–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º, –ø–∏—à–∏—Ç–µ –≤ tg: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –¥–æ–ø —Ñ–∞–π–ª–æ–≤\n",
        "!python download_files.py &> /dev/null\n",
        "\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!pip install --no-cache-dir -qq python-dotenv torchcrepe fairseq pyworld praat-parselmouth ffmpeg-python faiss-cpu av &> /dev/null\n",
        "\n",
        "!wget https://files.pythonhosted.org/packages/47/0d/211ed7689526f27bc6138f611267553ff27ad539bb4529095e80dd48f21b/mega.py-1.0.8.tar.gz -P /content/CoverGen/ &> /dev/null\n",
        "!pip install \\mega.py-1.0.8.tar.gz &> /dev/null\n",
        "!rm -rf \\mega.py-1.0.8.tar.gz\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø–∞–ø–æ–∫\n",
        "!mkdir -p /content/input\n",
        "!mkdir -p /content/output\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8iG9b05oHCbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üîä **–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –≤–æ–∫–∞–ª–æ–º**\n",
        "\n",
        "#@markdown –ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π —Ñ–∞–π–ª –≤—Ä—É—á–Ω—É—é –≤ –ø–∞–ø–∫—É <big> **`input`**\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "\n",
        "# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã\n",
        "INPUT_DIR = \"/content/input\"\n",
        "VOCAL_FILE_NAME = \"vocal\"\n",
        "ALLOWED_EXTENSIONS = {'.mp3', '.wav'}\n",
        "\n",
        "os.chdir(INPUT_DIR)\n",
        "!rm -r /content/input/*\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –≤–æ–∫–∞–ª–æ–º\n",
        "audio = files.upload()\n",
        "clear_output()\n",
        "\n",
        "if not audio:\n",
        "    print(\"–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª.\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
        "ext = os.path.splitext(list(audio.keys())[-1])[-1].lower()\n",
        "if ext not in ALLOWED_EXTENSIONS:\n",
        "    !rm -r /content/input/*\n",
        "    print(f\"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ '{ext}'. –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —Å —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ {', '.join(ALLOWED_EXTENSIONS)}.\")\n",
        "    print(\"–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –¥—Ä—É–≥–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º, —Ç–æ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –µ–≥–æ –≤—Ä—É—á–Ω—É—é –≤ –ø–∞–ø–∫—É input.\")\n",
        "\n",
        "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "input_audio = VOCAL_FILE_NAME + ext\n",
        "os.rename(list(audio.keys())[-1], input_audio)\n",
        "\n",
        "clear_output()\n",
        "print(f\"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")"
      ],
      "metadata": {
        "id": "ACOFLHXKG85B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üîé **–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏**\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br><center><img src='https://mega.nz/favicon.ico?v=3' height=\"60\" alt=\"MEGA-logo\"/> <img src='https://github.com/DiyRex/Torrent-to-G-Drive-/blob/main/google_drive_new_logo-512.png?raw=true' height=\"60\" alt=\"Gdrive-logo\"/> <img src='https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg' height=\"60\" alt=\"HuggingFace-logo\"/> <big> **–ò –î–†–£–ì–ò–ï** </center>\n",
        "\n",
        "url = ''  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <center><big> –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∏–ª–∏ –Ω–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è, —ç—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å, —á—Ç–æ –≤—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –∏–ª–∏ —Å—Å—ã–ª–∫—É —Å –∑–∞–∫—Ä—ã—Ç—ã–º –¥–æ—Å—Ç—É–ø–æ–º.\n",
        "\n",
        "%cd /content/CoverGen\n",
        "\n",
        "from mega.mega import Mega\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import urllib.parse\n",
        "from google.oauth2.service_account import Credentials\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import hashlib\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "\n",
        "!rm -rf /content/unzips/\n",
        "!rm -rf /content/zips/\n",
        "!mkdir /content/unzips\n",
        "!mkdir /content/zips\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            if filename == \".DS_Store\" or filename.startswith(\"._\"):\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            sanitize_directory(file_path)\n",
        "\n",
        "model_zip = urlparse(url).path.split('/')[-2] + '.zip'\n",
        "model_zip_path = '/content/zips/' + model_zip\n",
        "\n",
        "private_model = False\n",
        "condition1 = False\n",
        "condition2 = False\n",
        "condition3 = False\n",
        "is_index_found = False\n",
        "\n",
        "if url != '':\n",
        "    MODEL = \"\"  # Initialize MODEL variable\n",
        "    !mkdir -p /content/CoverGen/logs/$MODEL\n",
        "    !mkdir -p /content/zips/\n",
        "    !mkdir -p /content/CoverGen/assets/weights/  # Create the 'weights' directory\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        if \"/view\" in url:\n",
        "            url_parts = url.split(\"/\")\n",
        "            file_id = url_parts[-2]\n",
        "            download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "        else:\n",
        "            download_url = url\n",
        "        !gdown $download_url --fuzzy -O \"$model_zip_path\"\n",
        "    elif \"/blob/\" in url:\n",
        "        url = url.replace(\"blob\", \"resolve\")\n",
        "        print(\"–†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–π URL:\", url)  # Print the resolved URL\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "    elif \"mega.nz\" in url:\n",
        "        m = Mega()\n",
        "        print(\"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Å MEGA....\")\n",
        "        m.download_url(url, '/content/zips')\n",
        "    elif \"/tree/main\" in url:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        temp_url = ''\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            if link['href'].endswith('.zip'):\n",
        "                temp_url = link['href']\n",
        "                break\n",
        "        if temp_url:\n",
        "            url = temp_url\n",
        "            print(\"–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π URL:\", url)  # Print the updated URL\n",
        "            url = url.replace(\"blob\", \"resolve\")\n",
        "            print(\"–†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–π URL:\", url)  # Print the resolved URL\n",
        "\n",
        "            if \"huggingface.co\" not in url:\n",
        "                url = \"https://huggingface.co\" + url\n",
        "\n",
        "            !wget \"$url\" -O \"$model_zip_path\"\n",
        "        else:\n",
        "            print(\"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª .zip.\")\n",
        "            # Handle the case when no .zip file is found\n",
        "    else:\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "\n",
        "    for filename in os.listdir(\"/content/zips\"):\n",
        "        if filename.endswith(\".zip\"):\n",
        "            zip_file = os.path.join(\"/content/zips\", filename)\n",
        "            shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n",
        "\n",
        "sanitize_directory(\"/content/unzips\")\n",
        "\n",
        "def find_pth_file(folder):\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".pth\"):\n",
        "                file_name = os.path.splitext(file)[0]\n",
        "                file_name = re.sub('_e\\d+_s\\d+', '', file_name)  # –£–¥–∞–ª—è–µ–º –ø—Ä–∏–ø–∏—Å–∫–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —à–∞–±–ª–æ–Ω—É \"_eXXX_sYYYY\"\n",
        "                if file_name.startswith(\"G_\") or file_name.startswith(\"P_\"):\n",
        "                    config_file = os.path.join(root, \"config.json\")\n",
        "                    if os.path.isfile(config_file):\n",
        "                        print(\"–û–±–Ω–∞—Ä—É–∂–µ–Ω —É—Å—Ç–∞—Ä–µ–≤—à–∏–π —Ñ–∞–π–ª .pth! –≠—Ç–æ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –º–µ—Ç–æ–¥–æ–º RVC. –ù–∞–π–¥–∏—Ç–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—É—é –º–æ–¥–µ–ª—å RVC!\")\n",
        "                    continue  # Continue searching for a valid file\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.getsize(file_path) > 100 * 1024 * 1024:  # Check file size in bytes (100MB)\n",
        "                    print(\"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–ø—Ä–∏–≥–æ–¥–Ω—ã–π —Ñ–∞–π–ª –æ–±—É—á–µ–Ω–∏—è:\", file)\n",
        "                    continue  # Continue searching for a valid file\n",
        "                return file_name\n",
        "    return None\n",
        "\n",
        "MODEL = find_pth_file(\"/content/unzips\")\n",
        "if MODEL is not None:\n",
        "    print(\"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª .pth:\", MODEL + \".pth\")\n",
        "else:\n",
        "    print(\"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª .pth –≤ —Ä–∞–∑–æ–±—Ä–∞–Ω–Ω–æ–º zip-—Ñ–∞–π–ª–µ.\")\n",
        "    print(\"–ï—Å–ª–∏ –≤—ã—à–µ —ç—Ç–æ–π –æ—à–∏–±–∫–∏ –µ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± '–û—Ç–∫–∞–∑–∞–Ω–æ –≤ –¥–æ—Å—Ç—É–ø–µ', –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö URL-–∞–¥—Ä–µ—Å–æ–≤ –≤ Google –¢–∞–±–ª–∏—Ü–∞—Ö –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏.\")\n",
        "    MODEL = \"\"\n",
        "    global condition3\n",
        "    condition3 = True\n",
        "\n",
        "index_path = \"\"\n",
        "\n",
        "def find_version_number(index_path):\n",
        "    if condition2 and not condition1:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "    filename = os.path.basename(index_path)\n",
        "\n",
        "    if filename.endswith(\"_v2.index\"):\n",
        "        return 'RVC v2'\n",
        "    elif filename.endswith(\"_v1.index\"):\n",
        "        return 'RVC v1'\n",
        "    else:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "if MODEL != \"\":\n",
        "    # Move model into logs folder\n",
        "    for root, dirs, files in os.walk('/content/unzips'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.endswith(\".index\"):\n",
        "                print(\"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª index:\", file)\n",
        "                is_index_found = False\n",
        "                condition1 = True\n",
        "                logs_folder = os.path.join('/content/CoverGen/logs', MODEL)\n",
        "                os.makedirs(logs_folder, exist_ok=True)  # Create the logs folder if it doesn't exist\n",
        "\n",
        "                # Delete identical .index file if it exists\n",
        "                if file.endswith(\".index\"):\n",
        "                    identical_index_path = os.path.join(logs_folder, file)\n",
        "                    if os.path.exists(identical_index_path):\n",
        "                        os.remove(identical_index_path)\n",
        "\n",
        "                shutil.move(file_path, logs_folder)\n",
        "                index_path = os.path.join(logs_folder, file)  # Set index_path variable\n",
        "\n",
        "            elif \"G_\" not in file and \"D_\" not in file and file.endswith(\".pth\"):\n",
        "                destination_path = f'/content/CoverGen/assets/weights/{MODEL}.pth'\n",
        "                if os.path.exists(destination_path):\n",
        "                    print(\"–í—ã —É–∂–µ —Å–∫–∞—á–∞–ª–∏ —ç—Ç—É –º–æ–¥–µ–ª—å...\")\n",
        "                shutil.move(file_path, destination_path)\n",
        "\n",
        "if condition1 is False:\n",
        "    logs_folder = os.path.join('/content/CoverGen/logs', MODEL)\n",
        "    os.makedirs(logs_folder, exist_ok=True)\n",
        "# this is here so it doesnt crash if the model is missing an index for some reason\n",
        "else:\n",
        "    print(\"URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Å—Ç–∞–≤–ª–µ–Ω –ø—É—Å—Ç—ã–º. –ï—Å–ª–∏ –≤—ã –Ω–µ —Ö–æ—Ç–∏—Ç–µ —Å–∫–∞—á–∏–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å–µ–π—á–∞—Å, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–µ —ç—Ç–æ—Ç —à–∞–≥.\")\n",
        "\n",
        "# –°–∫–∞—á–∏–≤–∞–µ–º –ª—é–±–æ–π index-—Ñ–∞–π–ª, –µ—Å–ª–∏ –≤ –∞—Ä—Ö–∏–≤–µ –µ–≥–æ –Ω–µ –±—ã–ª–æ\n",
        "if is_index_found is False:\n",
        "  logs_folder = os.path.join('/content/CoverGen/logs', MODEL)\n",
        "  index_path = os.path.join(logs_folder, 'model.index')\n",
        "  if os.path.exists(index_path) == False:\n",
        "    !wget 'https://huggingface.co/sail-rvc/2001MJAIDAM/resolve/main/model.index' -P {logs_folder}\n",
        "\n",
        "!rm -r /content/unzips/\n",
        "!rm -r /content/zips/\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "clear_output()\n",
        "\n",
        "os.chdir('/content/CoverGen/assets/weights')\n",
        "print(\"\\n–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:\\n\")\n",
        "files = [f for f in os.listdir('.') if f.endswith('.pth')]\n",
        "for file in files:\n",
        "    print(file[:-4])\n"
      ],
      "metadata": {
        "id": "loDUWLJvHIOy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üó£Ô∏è **–ó–∞–º–µ–Ω–∞ –≥–æ–ª–æ—Å–∞**\n",
        "\n",
        "import os\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output, display, Audio\n",
        "from google.colab import files\n",
        "from ipywidgets import Button\n",
        "\n",
        "%cd /content/CoverGen\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–í–≤–µ–¥–∏—Ç–µ –∏–º—è –º–æ–¥–µ–ª–∏:**\n",
        "model_name = \"Model_Name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–∞:**\n",
        "method = \"rmvpe\" #@param [\"rmvpe\", \"pm\", \"harvest\"] {allow-input: false}\n",
        "#@markdown **–í—ã—Å–æ—Ç–∞ —Ç–æ–Ω–∞ –≥–æ–ª–æ—Å–∞ ( -12 - –Ω–∞ –æ–∫—Ç–∞–≤—É –Ω–∏–∂–µ, 0 - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—É—é –≤—ã—Å–æ—Ç—É, 12 - –Ω–∞ –æ–∫—Ç–∞–≤—É –≤—ã—à–µ ):**\n",
        "pitch = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**\n",
        "\n",
        "#@markdown <small> –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∞–∫—Ü–µ–Ω—Ç –≥–æ–ª–æ—Å–∞ –ò–ò –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –≤–æ–∫–∞–ª–µ:\n",
        "index_rate = 0.66 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "volume_normalization = 1\n",
        "#@markdown <small> –ó–∞—â–∏—Ç–∞ –±–µ–∑–≥–æ–ª–æ—Å—ã—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö –∏ –∑–≤—É–∫–æ–≤ –¥—ã—Ö–∞–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. –£–º–µ–Ω—å—à–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É—Å–∏–ª–∏—Ç—å –∑–∞—â–∏—Ç—É, –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
        "consonant_protection = 0 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "#@markdown <small> –ï—Å–ª–∏ >=3: –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –º–µ–¥–∏–∞–Ω–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∫ —Å–æ–±—Ä–∞–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–∏—Ç—á–∞. –ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Ä–∞–¥–∏—É—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ –º–æ–∂–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å –¥—ã—Ö–∞–Ω–∏–µ:\n",
        "filter_radius = 3 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "is_half = False\n",
        "#@markdown **–§–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:**\n",
        "format = \"mp3\" #@param [\"mp3\", \"wav\", \"flac\"] {allow-input: false}\n",
        "\n",
        "input_path = '/content/input/*.*'\n",
        "model_path = f'{model_name}.pth'\n",
        "index_path = f'logs/{model_name}/added_*_{model_name}_v2.index'\n",
        "opt_path = f'/content/output/output.{format}'\n",
        "\n",
        "# –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –Ω–æ–≤–æ–≥–æ\n",
        "!rm -r /content/output/*\n",
        "\n",
        "# –°–∫—Ä–∏–ø—Ç –∑–∞–º–µ–Ω—è—é—â–∏–π –≥–æ–ª–æ—Å\n",
        "!python tools/infer_cli.py --f0up_key $pitch --input_path $input_path --index_path $index_path --f0method $method --opt_path $opt_path --model_name $model_path --index_rate $index_rate --device cuda --is_half $is_half --filter_radius $filter_radius --resample_sr 0 --rms_mix_rate $volume_normalization --protect $consonant_protection\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <big><big> **–ü–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É –µ—Å–ª–∏ –≤—ã–ª–µ–∑–ª–∞ –æ—à–∏–±–∫–∞ –∏–ª–∏ –Ω–µ –ø–æ—è–≤–∏–ª—Å—è —Ñ–∞–π–ª, –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Å–∫–∏–Ω—å—Ç–µ —Å–∫—Ä–∏–Ω –æ—à–∏–±–∫–∏ –≤ —Ç–≥ https://t.me/+GMTP7hZqY0E4OGRi**\n",
        "check_error = False #@param {type:\"boolean\"}\n",
        "if not check_error:\n",
        "    ipd.clear_output()\n",
        "\n",
        "# –í—ã–≤–æ–¥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ \"–°–∫–∞—á–∞—Ç—å\"\n",
        "def download_file(file_path):\n",
        "    files.download(file_path)\n",
        "\n",
        "print(\"\\nGoogle Colab –∏–Ω–æ–≥–¥–∞ –Ω–µ –º–æ–∂–µ—Ç –≤—ã–≤–µ—Å—Ç–∏ –æ–∫–Ω–æ —Å –∞—É–¥–∏–æ, –ø–æ—ç—Ç–æ–º—É:\\n\")\n",
        "print(\"\\n1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–≤–æ–¥–∏–º –∫–Ω–æ–ø–∫—É '–°–∫–∞—á–∞—Ç—å', –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –≤—ã –º–æ–∂–µ—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –Ω–∞ –≤–∞—à–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.\\n\")\n",
        "\n",
        "download_button = Button(description=\"–°–∫–∞—á–∞—Ç—å\")\n",
        "display(download_button)\n",
        "download_button.on_click(lambda _: download_file(opt_path))\n",
        "\n",
        "print(\"\\n2. –ó–∞—Ç–µ–º, –í—ã–≤–æ–¥–∏–º —Å–∞–º—É –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –ø—Ä—è–º–æ –≤ Google Colab.\\n\")\n",
        "\n",
        "display(Audio(f\"{opt_path}\", rate=44100))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pk3iGUqoHLyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–í–ï–†–û–í**"
      ],
      "metadata": {
        "id": "Uh_yZExjWHRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üöÄ **–£–°–¢–ê–ù–û–í–ö–ê**\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import torch\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!\")\n",
        "    raise Exception('–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ GPU –Ω–∞ –≤–∞—à–µ–º —Ç–µ–∫—É—â–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ GPU, –∏–ª–∏ –ø–æ–¥–æ–∂–¥–∏—Ç–µ 24 —á–∞—Å–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É.')\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤\n",
        "!git clone https://github.com/Bebra777228/TrainVocModel-EN /content/CoverGen  &> /dev/null\n",
        "!git clone https://github.com/jarredou/MVSEP-MDX23-Colab_v2 /content/CoverGen/UVR  &> /dev/null\n",
        "%cd /content/CoverGen\n",
        "clear_output()\n",
        "\n",
        "print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 5 –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
        "print('\\n–ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–π–º–µ—Ç –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç, —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ–Ω–∞ –∑–∞–≤–∏—Å–ª–∞ –∏ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å colab. \\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é \"–°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\" -> \"–û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —É–¥–∞–ª–∏—Ç—å –µ–µ\", –ª–∏–±–æ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–π –∞–∫–∫–∞—É–Ω—Ç.')\n",
        "print(\"\\n–ü–æ –ª—é–±—ã–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º, –ø–∏—à–∏—Ç–µ –≤ tg: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "# –û–±—Ñ—É—Å–∫–∞—Ü–∏—è\n",
        "hug_user = \"https\"+\"://hugg\"+\"ingface.co/seang\"+\"hay/uv\"+\"r_models/res\"+\"olve/main/\"\n",
        "a_hug_model = \"9_HP\"+\"2-UV\"+\"R.p\"+\"th\"\n",
        "b_hug_model = \"UV\"+\"R-DeE\"+\"cho-DeRe\"+\"verb.p\"+\"th\"\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
        "!python download_files.py &> /dev/null\n",
        "!wget {hug_user}{a_hug_model} -P /content/CoverGen/assets/uvr5_weights/  &> /dev/null\n",
        "!wget {hug_user}{b_hug_model} -P /content/CoverGen/assets/uvr5_weights/  &> /dev/null\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!pip install --no-cache-dir -qq -r /content/CoverGen/UVR/requirements.txt &> /dev/null\n",
        "!apt-get -y install build-essential python3-dev &> /dev/null\n",
        "!pip install --no-cache-dir -qq --upgrade setuptools wheel pip &> /dev/null\n",
        "!pip install --no-cache-dir -qq librosa==0.9.1 python-dotenv torchcrepe fairseq pyworld praat-parselmouth ffmpeg-python faiss-cpu av stftpitchshift &> /dev/null\n",
        "\n",
        "!python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/  &> /dev/null\n",
        "\n",
        "!wget https://files.pythonhosted.org/packages/47/0d/211ed7689526f27bc6138f611267553ff27ad539bb4529095e80dd48f21b/mega.py-1.0.8.tar.gz -P /content/CoverGen/ &> /dev/null\n",
        "!pip install --no-cache-dir -qq \\mega.py-1.0.8.tar.gz &> /dev/null\n",
        "!rm -rf \\mega.py-1.0.8.tar.gz\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø–∞–ø–æ–∫\n",
        "!mkdir -p /content/input\n",
        "!mkdir -p /content/output/ouvr\n",
        "!mkdir -p /content/output/processed\n",
        "!mkdir -p /content/output/no_processed\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\")"
      ],
      "metadata": {
        "id": "Rqfkq7TbWOM5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>‚úÇÔ∏è **–†–ê–ó–î–ï–õ–ï–ù–ò–ï**\n",
        "\n",
        "from IPython.display import clear_output, Audio, display\n",
        "from ipywidgets import Button\n",
        "from google.colab import files\n",
        "from pathlib import Path, PurePath\n",
        "import IPython.display as ipd\n",
        "import os, time\n",
        "import ffmpeg\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "# --------------------\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–µ—Å–Ω–∏\n",
        "# --------------------\n",
        "\n",
        "%cd /content/input\n",
        "!rm /content/input/*.*\n",
        "!rm /content/output/ouvr/*.*\n",
        "clear_output()\n",
        "audio = files.upload()\n",
        "\n",
        "ext = os.path.splitext(list(audio.keys())[-1])[-1]\n",
        "os.rename(list(audio.keys())[-1], \"Music{}\".format(ext))\n",
        "input_audio = \"Music\" + ext\n",
        "clear_output()\n",
        "\n",
        "# ---------------------------------\n",
        "# –û—Ç–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∫–∞–ª–∞ –æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª–∞\n",
        "# ---------------------------------\n",
        "\n",
        "%cd /content/CoverGen/UVR\n",
        "\n",
        "input = '/content/input'\n",
        "output_uvr_folder = '/content/output/ouvr'\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown –£—Å–∏–ª–µ–Ω–∏–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ (–æ—Ç 0 –¥–æ 6)\n",
        "gain = 0 #@param {type:\"slider\", min:0, max:6, step:3}\n",
        "#@markdown –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É—Å–∏–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
        "restore_gain = False #@param {type:\"boolean\"}\n",
        "#@markdown –£–¥–∞–ª–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤ –Ω–∏–∂–µ 50 –ì—Ü –≤ –≤–æ–∫–∞–ª–µ\n",
        "filter_vocals = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è:\n",
        "\n",
        "VitLarge = False #@param {type:\"boolean\"}\n",
        "InstHQ4 = False #@param {type:\"boolean\"}\n",
        "VOCFT = False #@param {type:\"boolean\"}\n",
        "#@markdown <small> **VOCFT - –ø—Ä–æ–∂–æ—Ä–ª–∏–≤–∞—è –º–æ–¥–µ–ª—å, –µ–µ –ª—É—á—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ —Å–≤—è–∑–∫–µ —Å InstHQ4 (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –∑–∞—Ç—è–Ω—É—Ç—å—Å—è –Ω–∞ —á–∞—Å+)**\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown –†–∞–∑–º–µ—Ä –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ—Ç—Ä–µ–∑–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞: ***(–±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–º—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é)***\n",
        "BigShifts = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "#@markdown –°—Ç–µ–ø–µ–Ω—å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—Ç—Ä–µ–∑–∫–æ–≤ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞: ***(–±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –±–æ–ª–µ–µ –≥–ª–∞–¥–∫–æ–º—É –∑–≤—É—á–∞–Ω–∏—é)***\n",
        "overlap = 0.6 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "\n",
        "#@markdown –í–µ—Å –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞: ***(–±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –±–æ–ª—å—à–µ–º—É –≤–ª–∏—è–Ω–∏—é –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç)***\n",
        "weight = 8 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "use_VitLarge = '--use_VitLarge' if VitLarge is True else ''\n",
        "use_InstHQ4 = '--use_InstHQ4' if InstHQ4 is True else ''\n",
        "use_VOCFT = '--use_VOCFT' if VOCFT is True else ''\n",
        "restore_gain_sound = '--restore_gain' if restore_gain is True else ''\n",
        "filter_vocals_50hz = '--filter_vocals' if filter_vocals is True else ''\n",
        "\n",
        "input = '/content/input'\n",
        "output_uvr_folder = '/content/output/ouvr'\n",
        "\n",
        "filename = next(Path(input).glob('*.mp3'))\n",
        "input_name = Path(filename).stem\n",
        "\n",
        "result = !python inference.py \\\n",
        "        --input_audio {filename} \\\n",
        "        --large_gpu \\\n",
        "        --BSRoformer_model \"ep_368_1296\" \\\n",
        "        --weight_BSRoformer {weight} \\\n",
        "        --weight_InstVoc {weight} \\\n",
        "        --weight_InstHQ4 {weight} \\\n",
        "        --weight_VOCFT {weight} \\\n",
        "        --weight_VitLarge {weight} \\\n",
        "        --overlap_demucs {overlap} \\\n",
        "        --overlap_VOCFT {overlap} \\\n",
        "        --overlap_InstHQ4 {overlap} \\\n",
        "        --output_format \"PCM_16\" \\\n",
        "        --BigShifts {BigShifts} \\\n",
        "        --output_folder {output_uvr_folder} \\\n",
        "        --input_gain {gain} \\\n",
        "        {filter_vocals_50hz} \\\n",
        "        {restore_gain_sound} \\\n",
        "        --vocals_only \\\n",
        "        {use_VitLarge} \\\n",
        "        {use_VOCFT} \\\n",
        "        {use_InstHQ4} \\\n",
        "        --use_InstVoc \\\n",
        "        --use_BSRoformer\n",
        "\n",
        "if len(result) > 0:\n",
        "    print(\"\\n–í—ã–≤–æ–¥ —Å–∫—Ä–∏–ø—Ç–∞ –≤—ã–≤–æ–¥–∞ UVR:\")\n",
        "    for line in result:\n",
        "        print(line)\n",
        "\n",
        "original = \"/content/input/Music.mp3\"\n",
        "vocal_file = \"/content/output/ouvr/Music_vocals.wav\"\n",
        "instrum_file = \"/content/output/ouvr/Music_instrum.wav\"\n",
        "denoised_vocal_file = \"/content/output/ouvr/denoised_Music_vocals.wav\"\n",
        "vocal = \"/content/output/ouvr/Music_vocals.mp3\"\n",
        "instrumental = \"/content/output/ouvr/Music_instrum.mp3\"\n",
        "\n",
        "%cd /content/CoverGen\n",
        "\n",
        "import numpy as np\n",
        "np.float = float\n",
        "\n",
        "from pathlib import Path, PurePath\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "\n",
        "input_denoise_file = vocal_file\n",
        "output_folder = PurePath(vocal_file).parent\n",
        "\n",
        "import os, sys, torch, warnings, pdb\n",
        "\n",
        "now_dir = os.getcwd()\n",
        "sys.path.append(now_dir)\n",
        "from json import load as ll\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import librosa\n",
        "import importlib\n",
        "import numpy as np\n",
        "import hashlib, math\n",
        "from tqdm import tqdm\n",
        "from lib.uvr5_pack.lib_v5 import spec_utils\n",
        "from lib.uvr5_pack.utils import _get_name_params, inference\n",
        "from lib.uvr5_pack.lib_v5.model_param_init import ModelParameters\n",
        "import soundfile as sf\n",
        "from lib.uvr5_pack.lib_v5.nets_new import CascadedNet\n",
        "from lib.uvr5_pack.lib_v5 import nets_61968KB as nets\n",
        "\n",
        "postprocess = False\n",
        "tta = True\n",
        "is_half = False\n",
        "window_size = 1024\n",
        "\n",
        "class _audio_pre_new:\n",
        "    def __init__(self, agg, model_path, device, is_half):\n",
        "        self.model_path = model_path\n",
        "        self.device = device\n",
        "        self.data = {\n",
        "            # Processing Options\n",
        "            \"postprocess\": postprocess,\n",
        "            \"tta\": tta,\n",
        "            # Constants\n",
        "            \"window_size\": window_size,\n",
        "            \"agg\": agg,\n",
        "            \"high_end_process\": \"mirroring\",\n",
        "        }\n",
        "        mp = ModelParameters(\"lib/uvr5_pack/lib_v5/modelparams/4band_v3.json\")\n",
        "        nout = 64 if \"DeReverb\" in model_path else 48\n",
        "        model = CascadedNet(mp.param[\"bins\"] * 2, nout)\n",
        "        cpk = torch.load(model_path, map_location=\"cuda\")\n",
        "        model.load_state_dict(cpk)\n",
        "        model.eval()\n",
        "        if is_half:\n",
        "            model = model.half().to(device)\n",
        "        else:\n",
        "            model = model.to(device)\n",
        "\n",
        "        self.mp = mp\n",
        "        self.model = model\n",
        "\n",
        "    def _path_audio_(\n",
        "        self, music_file, vocal_root=None, ins_root=None, format=\"flac\"\n",
        "    ):\n",
        "        if ins_root is None and vocal_root is None:\n",
        "            return \"No save root.\"\n",
        "        name = os.path.basename(music_file)\n",
        "        if ins_root is not None:\n",
        "            os.makedirs(ins_root, exist_ok=True)\n",
        "        if vocal_root is not None:\n",
        "            os.makedirs(vocal_root, exist_ok=True)\n",
        "        X_wave, y_wave, X_spec_s, y_spec_s = {}, {}, {}, {}\n",
        "        bands_n = len(self.mp.param[\"band\"])\n",
        "        for d in range(bands_n, 0, -1):\n",
        "            bp = self.mp.param[\"band\"][d]\n",
        "            if d == bands_n:  # high-end band\n",
        "                (\n",
        "                    X_wave[d],\n",
        "                    _,\n",
        "                ) = librosa.core.load(\n",
        "                    music_file,\n",
        "                    bp[\"sr\"],\n",
        "                    False,\n",
        "                    dtype=np.float32,\n",
        "                    res_type=bp[\"res_type\"],\n",
        "                )\n",
        "                if X_wave[d].ndim == 1:\n",
        "                    X_wave[d] = np.asfortranarray([X_wave[d], X_wave[d]])\n",
        "            else:  # lower bands\n",
        "                X_wave[d] = librosa.core.resample(\n",
        "                    X_wave[d + 1],\n",
        "                    self.mp.param[\"band\"][d + 1][\"sr\"],\n",
        "                    bp[\"sr\"],\n",
        "                    res_type=bp[\"res_type\"],\n",
        "                )\n",
        "            # Stft of wave source\n",
        "            X_spec_s[d] = spec_utils.wave_to_spectrogram_mt(\n",
        "                X_wave[d],\n",
        "                bp[\"hl\"],\n",
        "                bp[\"n_fft\"],\n",
        "                self.mp.param[\"mid_side\"],\n",
        "                self.mp.param[\"mid_side_b2\"],\n",
        "                self.mp.param[\"reverse\"],\n",
        "            )\n",
        "            # pdb.set_trace()\n",
        "            if d == bands_n and self.data[\"high_end_process\"] != \"none\":\n",
        "                input_high_end_h = (bp[\"n_fft\"] // 2 - bp[\"crop_stop\"]) + (\n",
        "                    self.mp.param[\"pre_filter_stop\"] - self.mp.param[\"pre_filter_start\"]\n",
        "                )\n",
        "                input_high_end = X_spec_s[d][\n",
        "                    :, bp[\"n_fft\"] // 2 - input_high_end_h : bp[\"n_fft\"] // 2, :\n",
        "                ]\n",
        "\n",
        "        X_spec_m = spec_utils.combine_spectrograms(X_spec_s, self.mp)\n",
        "        aggresive_set = float(self.data[\"agg\"] / 100)\n",
        "        aggressiveness = {\n",
        "            \"value\": aggresive_set,\n",
        "            \"split_bin\": self.mp.param[\"band\"][1][\"crop_stop\"],\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            pred, X_mag, X_phase = inference(\n",
        "                X_spec_m, self.device, self.model, aggressiveness, self.data\n",
        "            )\n",
        "        # Postprocess\n",
        "        if self.data[\"postprocess\"]:\n",
        "            pred_inv = np.clip(X_mag - pred, 0, np.inf)\n",
        "            pred = spec_utils.mask_silence(pred, pred_inv)\n",
        "        y_spec_m = pred * X_phase\n",
        "        v_spec_m = X_spec_m - y_spec_m\n",
        "\n",
        "        if ins_root is not None:\n",
        "            if self.data[\"high_end_process\"].startswith(\"mirroring\"):\n",
        "                input_high_end_ = spec_utils.mirroring(\n",
        "                    self.data[\"high_end_process\"], y_spec_m, input_high_end, self.mp\n",
        "                )\n",
        "                wav_instrument = spec_utils.cmb_spectrogram_to_wave(\n",
        "                    y_spec_m, self.mp, input_high_end_h, input_high_end_\n",
        "                )\n",
        "            else:\n",
        "                wav_instrument = spec_utils.cmb_spectrogram_to_wave(y_spec_m, self.mp)\n",
        "            if format in [\"wav\", \"flac\"]:\n",
        "                sf.write(\n",
        "                    os.path.join(\n",
        "                        ins_root,\n",
        "                        \"denoised_{}\".format(name),\n",
        "                    ),\n",
        "                    (np.array(wav_instrument) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "            else:\n",
        "                path = os.path.join(\n",
        "                    ins_root, \"denoised_{}.wav\".format(name)\n",
        "                )\n",
        "                sf.write(\n",
        "                    path,\n",
        "                    (np.array(wav_instrument) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "                if os.path.exists(path):\n",
        "                    os.system(\n",
        "                        \"ffmpeg -i %s -vn %s -q:a 2 -y\"\n",
        "                        % (path, path[:-4] + \".%s\" % format)\n",
        "                    )\n",
        "        if vocal_root is not None:\n",
        "            if self.data[\"high_end_process\"].startswith(\"mirroring\"):\n",
        "                input_high_end_ = spec_utils.mirroring(\n",
        "                    self.data[\"high_end_process\"], v_spec_m, input_high_end, self.mp\n",
        "                )\n",
        "                wav_vocals = spec_utils.cmb_spectrogram_to_wave(\n",
        "                    v_spec_m, self.mp, input_high_end_h, input_high_end_\n",
        "                )\n",
        "            else:\n",
        "                wav_vocals = spec_utils.cmb_spectrogram_to_wave(v_spec_m, self.mp)\n",
        "            if format in [\"wav\", \"flac\"]:\n",
        "                sf.write(\n",
        "                    os.path.join(\n",
        "                        vocal_root,\n",
        "                        \"vocal_{}_{}\".format(name, self.data[\"agg\"]),\n",
        "                    ),\n",
        "                    (np.array(wav_vocals) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "            else:\n",
        "                path = os.path.join(\n",
        "                    vocal_root, \"vocal_{}_{}.wav\".format(name, self.data[\"agg\"])\n",
        "                )\n",
        "                sf.write(\n",
        "                    path,\n",
        "                    (np.array(wav_vocals) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "                if os.path.exists(path):\n",
        "                    os.system(\n",
        "                        \"ffmpeg -i %s -vn %s -q:a 2 -y\"\n",
        "                        % (path, path[:-4] + \".%s\" % format)\n",
        "                    )\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "model_path = \"assets/uvr5_weights/UVR-DeEcho-DeReverb.pth\"\n",
        "pre_fun = _audio_pre_new(model_path=model_path, device=device, is_half=is_half, agg=10)\n",
        "pre_fun._path_audio_(input_denoise_file, None, output_folder, \"wav\")\n",
        "\n",
        "%mv {os.path.join(os.path.dirname(vocal_file), \"denoised_\" + os.path.basename(vocal_file)) + PurePath(vocal_file).suffix} {vocal_file}\n",
        "\n",
        "!ffmpeg -i {denoised_vocal_file} {vocal}\n",
        "!ffmpeg -i {instrum_file} {instrumental}\n",
        "\n",
        "#@markdown **–ü–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É –µ—Å–ª–∏ –≤—ã–ª–µ–∑–ª–∞ –æ—à–∏–±–∫–∞ –∏–ª–∏ –Ω–µ –ø–æ—è–≤–∏–ª—Å—è —Ñ–∞–π–ª, –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Å–∫–∏–Ω—å—Ç–µ —Å–∫—Ä–∏–Ω –æ—à–∏–±–∫–∏ –≤ —Ç–≥ https://t.me/+GMTP7hZqY0E4OGRi**\n",
        "check_error = False #@param {type:\"boolean\"}\n",
        "if not check_error:\n",
        "    ipd.clear_output()\n",
        "\n",
        "print(\"–û–†–ò–ì–ò–ù–ê–õ:\")\n",
        "display(Audio(original, autoplay=False))\n",
        "time.sleep(2)\n",
        "print(\"\\n\\n\\n–í–û–ö–ê–õ:\")\n",
        "time.sleep(1)\n",
        "display(Audio(vocal, autoplay=False))\n",
        "time.sleep(2)\n",
        "print(\"\\n\\n–ò–ù–°–¢–†–£–ú–ï–ù–¢–ê–õ:\")\n",
        "time.sleep(1)\n",
        "display(Audio(instrumental, autoplay=False))\n",
        "\n",
        "!rm /content/output/ouvr/*.wav\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h2zRto6p8Lvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üîé **–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏**\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br><center><img src='https://mega.nz/favicon.ico?v=3' height=\"60\" alt=\"MEGA-logo\"/> <img src='https://github.com/DiyRex/Torrent-to-G-Drive-/blob/main/google_drive_new_logo-512.png?raw=true' height=\"60\" alt=\"Gdrive-logo\"/> <img src='https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg' height=\"60\" alt=\"HuggingFace-logo\"/> <big> **–ò –î–†–£–ì–ò–ï** </center>\n",
        "\n",
        "url = ''  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <center><big> –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∏–ª–∏ –Ω–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è, —ç—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å, —á—Ç–æ –≤—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –∏–ª–∏ —Å—Å—ã–ª–∫—É —Å –∑–∞–∫—Ä—ã—Ç—ã–º –¥–æ—Å—Ç—É–ø–æ–º.\n",
        "\n",
        "%cd /content/CoverGen\n",
        "\n",
        "from mega.mega import Mega\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import urllib.parse\n",
        "from google.oauth2.service_account import Credentials\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import hashlib\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "\n",
        "!rm -rf /content/unzips/\n",
        "!rm -rf /content/zips/\n",
        "!mkdir /content/unzips\n",
        "!mkdir /content/zips\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            if filename == \".DS_Store\" or filename.startswith(\"._\"):\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            sanitize_directory(file_path)\n",
        "\n",
        "model_zip = urlparse(url).path.split('/')[-2] + '.zip'\n",
        "model_zip_path = '/content/zips/' + model_zip\n",
        "\n",
        "private_model = False\n",
        "condition1 = False\n",
        "condition2 = False\n",
        "condition3 = False\n",
        "is_index_found = False\n",
        "\n",
        "if url != '':\n",
        "    MODEL = \"\"  # Initialize MODEL variable\n",
        "    !mkdir -p /content/CoverGen/logs/$MODEL\n",
        "    !mkdir -p /content/zips/\n",
        "    !mkdir -p /content/CoverGen/assets/weights/  # Create the 'weights' directory\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        if \"/view\" in url:\n",
        "            url_parts = url.split(\"/\")\n",
        "            file_id = url_parts[-2]\n",
        "            download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "        else:\n",
        "            download_url = url\n",
        "        !gdown $download_url --fuzzy -O \"$model_zip_path\"\n",
        "    elif \"/blob/\" in url:\n",
        "        url = url.replace(\"blob\", \"resolve\")\n",
        "        print(\"–†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–π URL:\", url)  # Print the resolved URL\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "    elif \"mega.nz\" in url:\n",
        "        m = Mega()\n",
        "        print(\"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Å MEGA....\")\n",
        "        m.download_url(url, '/content/zips')\n",
        "    elif \"/tree/main\" in url:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        temp_url = ''\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            if link['href'].endswith('.zip'):\n",
        "                temp_url = link['href']\n",
        "                break\n",
        "        if temp_url:\n",
        "            url = temp_url\n",
        "            print(\"–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π URL:\", url)  # Print the updated URL\n",
        "            url = url.replace(\"blob\", \"resolve\")\n",
        "            print(\"–†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–π URL:\", url)  # Print the resolved URL\n",
        "\n",
        "            if \"huggingface.co\" not in url:\n",
        "                url = \"https://huggingface.co\" + url\n",
        "\n",
        "            !wget \"$url\" -O \"$model_zip_path\"\n",
        "        else:\n",
        "            print(\"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª .zip.\")\n",
        "            # Handle the case when no .zip file is found\n",
        "    else:\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "\n",
        "    for filename in os.listdir(\"/content/zips\"):\n",
        "        if filename.endswith(\".zip\"):\n",
        "            zip_file = os.path.join(\"/content/zips\", filename)\n",
        "            shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n",
        "\n",
        "sanitize_directory(\"/content/unzips\")\n",
        "\n",
        "def find_pth_file(folder):\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".pth\"):\n",
        "                file_name = os.path.splitext(file)[0]\n",
        "                file_name = re.sub('_e\\d+_s\\d+', '', file_name)  # –£–¥–∞–ª—è–µ–º –ø—Ä–∏–ø–∏—Å–∫–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —à–∞–±–ª–æ–Ω—É \"_eXXX_sYYYY\"\n",
        "                if file_name.startswith(\"G_\") or file_name.startswith(\"P_\"):\n",
        "                    config_file = os.path.join(root, \"config.json\")\n",
        "                    if os.path.isfile(config_file):\n",
        "                        print(\"–û–±–Ω–∞—Ä—É–∂–µ–Ω —É—Å—Ç–∞—Ä–µ–≤—à–∏–π —Ñ–∞–π–ª .pth! –≠—Ç–æ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –º–µ—Ç–æ–¥–æ–º RVC. –ù–∞–π–¥–∏—Ç–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—É—é –º–æ–¥–µ–ª—å RVC!\")\n",
        "                    continue  # Continue searching for a valid file\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.getsize(file_path) > 100 * 1024 * 1024:  # Check file size in bytes (100MB)\n",
        "                    print(\"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–ø—Ä–∏–≥–æ–¥–Ω—ã–π —Ñ–∞–π–ª –æ–±—É—á–µ–Ω–∏—è:\", file)\n",
        "                    continue  # Continue searching for a valid file\n",
        "                return file_name\n",
        "    return None\n",
        "\n",
        "MODEL = find_pth_file(\"/content/unzips\")\n",
        "if MODEL is not None:\n",
        "    print(\"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª .pth:\", MODEL + \".pth\")\n",
        "else:\n",
        "    print(\"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª .pth –≤ —Ä–∞–∑–æ–±—Ä–∞–Ω–Ω–æ–º zip-—Ñ–∞–π–ª–µ.\")\n",
        "    print(\"–ï—Å–ª–∏ –≤—ã—à–µ —ç—Ç–æ–π –æ—à–∏–±–∫–∏ –µ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± '–û—Ç–∫–∞–∑–∞–Ω–æ –≤ –¥–æ—Å—Ç—É–ø–µ', –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö URL-–∞–¥—Ä–µ—Å–æ–≤ –≤ Google –¢–∞–±–ª–∏—Ü–∞—Ö –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏.\")\n",
        "    MODEL = \"\"\n",
        "    global condition3\n",
        "    condition3 = True\n",
        "\n",
        "index_path = \"\"\n",
        "\n",
        "def find_version_number(index_path):\n",
        "    if condition2 and not condition1:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "    filename = os.path.basename(index_path)\n",
        "\n",
        "    if filename.endswith(\"_v2.index\"):\n",
        "        return 'RVC v2'\n",
        "    elif filename.endswith(\"_v1.index\"):\n",
        "        return 'RVC v1'\n",
        "    else:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "if MODEL != \"\":\n",
        "    # Move model into logs folder\n",
        "    for root, dirs, files in os.walk('/content/unzips'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.endswith(\".index\"):\n",
        "                print(\"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª index:\", file)\n",
        "                is_index_found = False\n",
        "                condition1 = True\n",
        "                logs_folder = os.path.join('/content/CoverGen/logs', MODEL)\n",
        "                os.makedirs(logs_folder, exist_ok=True)  # Create the logs folder if it doesn't exist\n",
        "\n",
        "                # Delete identical .index file if it exists\n",
        "                if file.endswith(\".index\"):\n",
        "                    identical_index_path = os.path.join(logs_folder, file)\n",
        "                    if os.path.exists(identical_index_path):\n",
        "                        os.remove(identical_index_path)\n",
        "\n",
        "                shutil.move(file_path, logs_folder)\n",
        "                index_path = os.path.join(logs_folder, file)  # Set index_path variable\n",
        "\n",
        "            elif \"G_\" not in file and \"D_\" not in file and file.endswith(\".pth\"):\n",
        "                destination_path = f'/content/CoverGen/assets/weights/{MODEL}.pth'\n",
        "                if os.path.exists(destination_path):\n",
        "                    print(\"–í—ã —É–∂–µ —Å–∫–∞—á–∞–ª–∏ —ç—Ç—É –º–æ–¥–µ–ª—å...\")\n",
        "                shutil.move(file_path, destination_path)\n",
        "\n",
        "if condition1 is False:\n",
        "    logs_folder = os.path.join('/content/CoverGen/logs', MODEL)\n",
        "    os.makedirs(logs_folder, exist_ok=True)\n",
        "# this is here so it doesnt crash if the model is missing an index for some reason\n",
        "else:\n",
        "    print(\"URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Å—Ç–∞–≤–ª–µ–Ω –ø—É—Å—Ç—ã–º. –ï—Å–ª–∏ –≤—ã –Ω–µ —Ö–æ—Ç–∏—Ç–µ —Å–∫–∞—á–∏–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å–µ–π—á–∞—Å, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–µ —ç—Ç–æ—Ç —à–∞–≥.\")\n",
        "\n",
        "# –°–∫–∞—á–∏–≤–∞–µ–º –ª—é–±–æ–π index-—Ñ–∞–π–ª, –µ—Å–ª–∏ –≤ –∞—Ä—Ö–∏–≤–µ –µ–≥–æ –Ω–µ –±—ã–ª–æ\n",
        "if is_index_found is False:\n",
        "  logs_folder = os.path.join('/content/CoverGen/logs', MODEL)\n",
        "  index_path = os.path.join(logs_folder, 'model.index')\n",
        "  if os.path.exists(index_path) == False:\n",
        "    !wget 'https://huggingface.co/sail-rvc/2001MJAIDAM/resolve/main/model.index' -P {logs_folder}\n",
        "\n",
        "!rm -r /content/unzips/\n",
        "!rm -r /content/zips/\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "clear_output()\n",
        "\n",
        "os.chdir('/content/CoverGen/assets/weights')\n",
        "print(\"\\n–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:\\n\")\n",
        "files = [f for f in os.listdir('.') if f.endswith('.pth')]\n",
        "for file in files:\n",
        "    print(file[:-4])\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rv1tXrArWTU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üó£Ô∏è **–ó–∞–º–µ–Ω–∞ –≥–æ–ª–æ—Å–∞**\n",
        "\n",
        "import os\n",
        "import ffmpeg\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output, display, Audio\n",
        "from google.colab import files\n",
        "from ipywidgets import Button\n",
        "\n",
        "%cd /content/CoverGen\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–í–≤–µ–¥–∏—Ç–µ –∏–º—è –º–æ–¥–µ–ª–∏:**\n",
        "model_name = \"Model_Name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–∞:**\n",
        "method = \"rmvpe\" #@param [\"rmvpe\", \"pm\", \"harvest\"] {allow-input: false}\n",
        "#@markdown **–í—ã—Å–æ—Ç–∞ —Ç–æ–Ω–∞ –≥–æ–ª–æ—Å–∞ ( -12 - –Ω–∞ –æ–∫—Ç–∞–≤—É –Ω–∏–∂–µ, 0 - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—É—é –≤—ã—Å–æ—Ç—É, 12 - –Ω–∞ –æ–∫—Ç–∞–≤—É –≤—ã—à–µ ):**\n",
        "pitch = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**\n",
        "\n",
        "#@markdown <small> –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∞–∫—Ü–µ–Ω—Ç –≥–æ–ª–æ—Å–∞ –ò–ò –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –≤–æ–∫–∞–ª–µ:\n",
        "index_rate = 0.66 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "volume_normalization = 1\n",
        "#@markdown <small> –ó–∞—â–∏—Ç–∞ –±–µ–∑–≥–æ–ª–æ—Å—ã—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö –∏ –∑–≤—É–∫–æ–≤ –¥—ã—Ö–∞–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. –£–º–µ–Ω—å—à–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É—Å–∏–ª–∏—Ç—å –∑–∞—â–∏—Ç—É, –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
        "consonant_protection = 0.2 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "#@markdown <small> –ï—Å–ª–∏ >=3: –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –º–µ–¥–∏–∞–Ω–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∫ —Å–æ–±—Ä–∞–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–∏—Ç—á–∞. –ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Ä–∞–¥–∏—É—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ –º–æ–∂–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å –¥—ã—Ö–∞–Ω–∏–µ:\n",
        "filter_radius = 3 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "is_half = False\n",
        "#@markdown **–§–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:**\n",
        "format = \"mp3\" #@param [\"mp3\", \"wav\", \"flac\"] {allow-input: false}\n",
        "\n",
        "input_path = '/content/output/ouvr/Music_vocals.mp3'\n",
        "model_path = f'{model_name}.pth'\n",
        "index_path = f'logs/{model_name}/added_*_{model_name}_v2.index'\n",
        "opt_path = f'/content/output/no_processed/output.{format}'\n",
        "\n",
        "# –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –Ω–æ–≤–æ–≥–æ\n",
        "!rm -r /content/output/no_processed/*\n",
        "\n",
        "# –°–∫—Ä–∏–ø—Ç –∑–∞–º–µ–Ω—è—é—â–∏–π –≥–æ–ª–æ—Å\n",
        "!python tools/infer_cli.py --f0up_key $pitch --input_path $input_path --index_path $index_path --f0method $method --opt_path $opt_path --model_name $model_path --index_rate $index_rate --device cuda --is_half $is_half --filter_radius $filter_radius --resample_sr 0 --rms_mix_rate $volume_normalization --protect $consonant_protection\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "output_path = '/content/output/no_processed'\n",
        "\n",
        "result_file = os.path.join(output_path, input_name + \".\" + format)\n",
        "\n",
        "!ffmpeg -y -i {opt_path} -i {instrumental} -filter_complex \"[0:a][1:a]amerge=inputs=2[a]\" -map \"[a]\" -ac 2 {result_file}\n",
        "\n",
        "#@markdown <big><big> **–ü–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É –µ—Å–ª–∏ –≤—ã–ª–µ–∑–ª–∞ –æ—à–∏–±–∫–∞ –∏–ª–∏ –Ω–µ –ø–æ—è–≤–∏–ª—Å—è —Ñ–∞–π–ª, –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Å–∫–∏–Ω—å—Ç–µ —Å–∫—Ä–∏–Ω –æ—à–∏–±–∫–∏ –≤ —Ç–≥ https://t.me/+GMTP7hZqY0E4OGRi**\n",
        "check_error = False #@param {type:\"boolean\"}\n",
        "if not check_error:\n",
        "    ipd.clear_output()\n",
        "\n",
        "# –í—ã–≤–æ–¥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ \"–°–∫–∞—á–∞—Ç—å\"\n",
        "def download_file(file_path):\n",
        "    files.download(file_path)\n",
        "\n",
        "print(\"\\nGoogle Colab –∏–Ω–æ–≥–¥–∞ –Ω–µ –º–æ–∂–µ—Ç –≤—ã–≤–µ—Å—Ç–∏ –æ–∫–Ω–æ —Å –∞—É–¥–∏–æ, –ø–æ—ç—Ç–æ–º—É:\\n\")\n",
        "print(\"\\n1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–≤–æ–¥–∏–º –∫–Ω–æ–ø–∫—É '–°–∫–∞—á–∞—Ç—å', –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –≤—ã –º–æ–∂–µ—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –Ω–∞ –≤–∞—à–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.\\n\")\n",
        "\n",
        "download_button = Button(description=\"–°–∫–∞—á–∞—Ç—å\")\n",
        "display(download_button)\n",
        "download_button.on_click(lambda _: download_file(result_file))\n",
        "\n",
        "print(\"\\n2. –ó–∞—Ç–µ–º, –í—ã–≤–æ–¥–∏–º —Å–∞–º—É –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –ø—Ä—è–º–æ –≤ Google Colab.\\n\")\n",
        "\n",
        "audio = Audio(result_file, autoplay=False)\n",
        "display(audio)\n",
        "\n",
        "print(\"\\n–≠—Ç–æ—Ç ai cover –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Å–µ–±–µ –Ω–∏–∫–∞–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏. (—è—á–µ–π–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–∞–≤–µ—Ä–∞ –±—É–¥–µ—Ç –ø–æ–∑–∂–µ)\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kh39gc0xWcFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üíæ  **–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤**\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #<big> UVR\n",
        "\n",
        "Download_UVR = \"None\" # @param [\"–í–æ–∫–∞–ª\", \"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª\", \"–í–æ–∫–∞–ª & –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª\"] {allow-input: true}\n",
        "\n",
        "if Download_UVR==\"–í–æ–∫–∞–ª\":\n",
        "  print('–°–∫–∞—á–∏–≤–∞–µ–º –í–æ–∫–∞–ª...')\n",
        "  files.download(f'/content/output/ouvr/Music_vocals.{format}')\n",
        "elif Download_UVR==\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª\":\n",
        "  print('–°–∫–∞—á–∏–≤–∞–µ–º –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª...')\n",
        "  files.download(f'/content/output/ouvr/Music_instrum.{format}')\n",
        "elif Download_UVR==\"–í–æ–∫–∞–ª & –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª\":\n",
        "  print('–°–∫–∞—á–∏–≤–∞–µ–º –í–æ–∫–∞–ª –∏ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª...')\n",
        "  files.download(f'/content/output/ouvr/Music_vocals.{format}')\n",
        "  files.download(f'/content/output/ouvr/Music_instrum.{format}')\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #<big> Ai Cover\n",
        "\n",
        "Download_Ai_Cover = \"None\" # @param [\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –í–æ–∫–∞–ª (–±–µ–∑ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤)\", \"–ì–æ—Ç–æ–≤—ã–π Ai Cover (–±–µ–∑ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤)\"] {allow-input: true}\n",
        "\n",
        "if Download_Ai_Cover==\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –í–æ–∫–∞–ª (–±–µ–∑ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤)\":\n",
        "  print('–°–∫–∞—á–∏–≤–∞–µ–º –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –í–æ–∫–∞–ª...')\n",
        "  files.download(f'/content/output/no_processed/output.{format}')\n",
        "elif Download_Ai_Cover==\"–ì–æ—Ç–æ–≤—ã–π Ai Cover (–±–µ–∑ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤)\":\n",
        "  print('–°–∫–∞—á–∏–≤–∞–µ–º Ai Cover...')\n",
        "  files.download(f'/content/output/no_processed/Music.{format}')\n",
        "\n",
        "#@markdown ---"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6JCPrHmckOG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FF8C00'> **<big> <<< UVR**"
      ],
      "metadata": {
        "id": "1TpE4J8mUy00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>üöÄ **–£–°–¢–ê–ù–û–í–ö–ê**\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "\n",
        "!mkdir -p /content/input\n",
        "\n",
        "!git clone https://github.com/Bebra777228/UVR-Colab /content/UVR &> /dev/null\n",
        "%cd /content/UVR\n",
        "\n",
        "!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n",
        "!python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/  &> /dev/null\n",
        "\n",
        "!mkdir -p /content/output\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "#@markdown **–ü–æ–¥–∫–ª—é—á–∏—Ç—å –≥—É–≥–ª –¥–∏—Å–∫ *(–±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–∞–º–∏)***\n",
        "GDrive = False #@param {type:\"boolean\"}\n",
        "if GDrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 –ì–æ—Ç–æ–≤–æ\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2HJLuO8kUyAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>‚úÇÔ∏è **–†–ê–ó–î–ï–õ–ï–ù–ò–ï**\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "%cd /content/UVR\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –ª–∏–±–æ –∫ –ø–∞–ø–∫–µ —Å —Ñ–∞–π–ª–∞–º–∏:**\n",
        "input = '/content/drive/MyDrive/input' #@param {type:\"string\"}\n",
        "output = '/content/drive/MyDrive/output' #@param {type:\"string\"}\n",
        "#@markdown > <small> –í input –ø–∞–ø–∫—É –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤.\n",
        "#@markdown ---\n",
        "#@markdown * **–ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è:**\n",
        "quality = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown ---\n",
        "#@markdown * **–ú–æ–¥–µ–ª–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è:**\n",
        "MDX23C_8KFFT_InstVoc_HQ = True # @param {type:\"boolean\"}\n",
        "BS_Roformer = True # @param {type:\"boolean\"}\n",
        "Mel_Band_Roformer = False # @param {type:\"boolean\"}\n",
        "Vit_Large = False # @param {type:\"boolean\"}\n",
        "UVR_MDX_NET_Inst_HQ_4 = False # @param {type:\"boolean\"}\n",
        "UVR_MDX_NET_Voc_FT = False # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "use_InstVoc = '--use_InstVoc' if MDX23C_8KFFT_InstVoc_HQ is True else ''\n",
        "use_BSRoformer = '--use_BSRoformer' if BS_Roformer is True else ''\n",
        "use_MelRoformer = '--use_MelRoformer' if Mel_Band_Roformer is True else ''\n",
        "use_VitLarge = '--use_VitLarge' if Vit_Large is True else ''\n",
        "use_InstHQ4 = '--use_InstHQ4' if UVR_MDX_NET_Inst_HQ_4 is True else ''\n",
        "use_VOCFT = '--use_VOCFT' if UVR_MDX_NET_Voc_FT is True else ''\n",
        "\n",
        "\n",
        "if Path(input).is_file():\n",
        "  file_path = input\n",
        "  Path(output).mkdir(parents=True, exist_ok=True)\n",
        "  !python inference.py \\\n",
        "        --input_audio \"{file_path}\" \\\n",
        "        --large_gpu \\\n",
        "        --weight_MelRoformer {quality} \\\n",
        "        --weight_BSRoformer {quality} \\\n",
        "        --weight_InstVoc {quality} \\\n",
        "        --weight_InstHQ4 {quality} \\\n",
        "        --weight_VOCFT {quality} \\\n",
        "        --weight_VitLarge {quality} \\\n",
        "        --overlap_MelRoformer {quality} \\\n",
        "        --overlap_BSRoformer {quality} \\\n",
        "        --overlap_demucs 1 \\\n",
        "        --overlap_VOCFT 1 \\\n",
        "        --overlap_InstHQ4 1 \\\n",
        "        --output_format \"FLAC\" \\\n",
        "        --BigShifts {quality} \\\n",
        "        --output_folder \"{output}\" \\\n",
        "        --vocals_only \\\n",
        "        {use_VitLarge} \\\n",
        "        {use_VOCFT} \\\n",
        "        {use_InstHQ4} \\\n",
        "        {use_MelRoformer} \\\n",
        "        {use_BSRoformer} \\\n",
        "        {use_InstVoc}\n",
        "\n",
        "\n",
        "else:\n",
        "    file_paths = sorted(glob.glob(input + \"/*\"))[:]\n",
        "    input_audio_args = ' '.join([f'\"{path}\"' for path in file_paths])\n",
        "    Path(output).mkdir(parents=True, exist_ok=True)\n",
        "    !python inference.py \\\n",
        "        --input_audio {input_audio_args} \\\n",
        "        --large_gpu \\\n",
        "        --weight_MelRoformer {quality} \\\n",
        "        --weight_BSRoformer {quality} \\\n",
        "        --weight_InstVoc {quality} \\\n",
        "        --weight_InstHQ4 {quality} \\\n",
        "        --weight_VOCFT {quality} \\\n",
        "        --weight_VitLarge {quality} \\\n",
        "        --overlap_MelRoformer {quality} \\\n",
        "        --overlap_BSRoformer {quality} \\\n",
        "        --overlap_demucs 1 \\\n",
        "        --overlap_VOCFT 1 \\\n",
        "        --overlap_InstHQ4 1 \\\n",
        "        --output_format \"FLAC\" \\\n",
        "        --BigShifts {quality} \\\n",
        "        --output_folder \"{output}\" \\\n",
        "        --vocals_only \\\n",
        "        {use_VitLarge} \\\n",
        "        {use_VOCFT} \\\n",
        "        {use_InstHQ4} \\\n",
        "        {use_MelRoformer} \\\n",
        "        {use_BSRoformer} \\\n",
        "        {use_InstVoc}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4chn0HHxVAzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FF8C00'> **<big> <<< GR–êDI–û**"
      ],
      "metadata": {
        "id": "AiyenwPubOAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< EasyGUI** <small><small>(–û—Ä–∏–≥–∏–Ω–∞–ª, –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ)"
      ],
      "metadata": {
        "id": "FffjiZTcAo26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='#00FFFF'><big> **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å RVC** ‚¨áÔ∏è\n",
        "%cd /content\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import subprocess, shlex, os\n",
        "from google.colab import drive\n",
        "\n",
        "var = \"We\"+\"bU\"+\"I\"\n",
        "test = \"Voice\"\n",
        "c_word = \"Conversion\"\n",
        "r_word = \"Retrieval\"\n",
        "!git clone https://github.com/RVC-Project/{r_word}-based-{test}-{c_word}-{var} /content/RVC\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "pretrains = [\"f0D32k.pth\",\"f0G32k.pth\"]\n",
        "new_pretrains = [\"f0Ov2Super32kD.pth\",\"f0Ov2Super32kG.pth\"]\n",
        "\n",
        "for file in pretrains:\n",
        "    if not os.path.exists(f\"/content/RVC/assets/pretrained_v2/{file}\"):\n",
        "        command = \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/%s%s%s/resolve/main/pretrained_v2/%s -d /content/RVC/assets/pretrained_v2 -o %s\" % (\"Voice\",\"Conversion\",\"WebUI\",file,file)\n",
        "        try:\n",
        "            subprocess.run(shlex.split(command))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "for file in new_pretrains:\n",
        "    if not os.path.exists(f\"/content/RVC/assets/pretrained_v2/{file}\"):\n",
        "        command = \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/%s -d /content/RVC/assets/pretrained_v2 -o %s\" % (file,file)\n",
        "        try:\n",
        "            subprocess.run(shlex.split(command))\n",
        "            print(shlex.split(command))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "!mkdir -p /content/dataset && mkdir -p /content/RVC/audios\n",
        "!wget -nc https://raw.githubusercontent.com/RejektsAI/EasyTools/main/original -O /content/RVC/original.py\n",
        "!wget -nc https://raw.githubusercontent.com/RejektsAI/EasyTools/main/app.py -O /content/RVC/demo.py\n",
        "!wget -nc https://raw.githubusercontent.com/RejektsAI/EasyTools/main/easyfuncs.py -O /content/RVC/easyfuncs.py\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/download_files.py -O /content/RVC/download_files.py\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/a.png -O /content/RVC/a.png\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/easy_sync.py -O /content/RVC/easy_sync.py\n",
        "!wget -nc https://huggingface.co/spaces/Rejekts/RVC_PlayGround/raw/main/app.py -O /content/RVC/playground.py\n",
        "!wget -nc https://huggingface.co/spaces/Rejekts/RVC_PlayGround/raw/main/tools/useftools.py -O /content/RVC/tools/useftools.py\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/astronauts.mp3 -O /content/RVC/audios/astronauts.mp3\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/somegirl.mp3 -O /content/RVC/audios/somegirl.mp3\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/someguy.mp3 -O /content/RVC/audios/someguy.mp3\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/unchico.mp3 -O /content/RVC/audios/unchico.mp3\n",
        "!wget -nc https://huggingface.co/Rejekts/project/resolve/main/unachica.mp3 -O /content/RVC/audios/unachica.mp3\n",
        "!cd /content/RVC && python /content/RVC/download_files.py\n",
        "\n",
        "if not \"installed\" in locals():\n",
        "    !cd /content/RVC && pip install -r requirements.txt\n",
        "    !pip install mega.py gdown==4.6.0 pytube pydub  gradio==3.42.0\n",
        "installed=True\n",
        "\n",
        "save_to_drive=False#@param {type:\"boolean\"}\n",
        "\n",
        "if save_to_drive:\n",
        "    try:\n",
        "        from google.colab import auth\n",
        "        from pydrive2.auth import GoogleAuth\n",
        "        from oauth2client.client import GoogleCredentials\n",
        "        from pydrive2.drive import GoogleDrive\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        my_drive = GoogleDrive(gauth)\n",
        "        drive.mount('/content/drive')\n",
        "        drive_trash = my_drive.ListFile({'q': \"trashed = true\"}).GetList()\n",
        "        from RVC.easy_sync import GarbageMan\n",
        "        kevin = GarbageMan()\n",
        "        kevin.start(path=drive_trash,every=40,pattern=\"[GD]_*.pth\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "from RVC.easy_sync import Channel\n",
        "logs_folder ='/content/drive/MyDrive/project-main/logs'\n",
        "weights_folder = '/content/drive/MyDrive/project-main/assets/weights'\n",
        "if not \"logs_backup\" in locals(): logs_backup = Channel('/content/RVC/logs',logs_folder,every=30,exclude=\"mute\")\n",
        "if not \"weights_backup\" in locals(): weights_backup = Channel('/content/RVC/assets/weights',weights_folder,every=30)\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    if not os.path.exists(logs_folder): os.makedirs(logs_folder)\n",
        "    if not os.path.exists(weights_folder): os.makedirs(weights_folder)\n",
        "    logs_backup.start()\n",
        "    weights_backup.start()\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Success\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wMJKYoqlbZFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='#00FFFF'><big> **–û—Ç–∫—Ä—ã—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** üì±\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "import shutil\n",
        "%cd /content/RVC\n",
        "load_models_from_drive = False #@param{type:\"boolean\"}\n",
        "open_tensorboard = True #@param{type:\"boolean\"}\n",
        "py = \"demo.py\"\n",
        "if load_models_from_drive:\n",
        "    if os.path.exists('/content/drive/MyDrive/project-main'):\n",
        "        for file in os.listdir('/content/drive/MyDrive/project-main/assets/weights'):\n",
        "            try: shutil.copy2(f'/content/drive/MyDrive/project-main/assets/weights/{file}','/content/RVC/assets/weights/')\n",
        "            except: print(f\"Error loading {file}\")\n",
        "        for file in os.listdir('/content/drive/MyDrive/project-main/logs'):\n",
        "            try: shutil.copytree(f'/content/drive/MyDrive/project-main/logs/{file}',f'/content/RVC/logs/{file}')\n",
        "            except: print(f\"Error loading {file}\")\n",
        "    else:\n",
        "        print(\"Google Drive not connected...\")\n",
        "if open_tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs --port=8888\n",
        "!python {py} --colab\n",
        "\n",
        "#@markdown ---"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e6pfI68EAzvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small>.</small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small>\n",
        "\n",
        "**[<center><big><big><big><big><big> –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –±–ª–æ–∫–Ω–æ—Ç </center>](https://colab.research.google.com/drive/1r4IRL0UA7JEoZ0ZK8PKfMyTIBHKpyhcw?usp=sharing)**\n",
        "# <small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small>.</small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small></small>"
      ],
      "metadata": {
        "id": "wbbSfRG4FOoP"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XnIUS5P9VauG",
        "O_27mvQ9mZjQ",
        "8q3V33sNvi6i",
        "h76D42owRGmD",
        "fZ3Kl6DJmtSF",
        "Gp-DFix6G3Uc",
        "Uh_yZExjWHRw",
        "1TpE4J8mUy00",
        "AiyenwPubOAs",
        "FffjiZTcAo26"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
